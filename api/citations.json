{
    "offset": 0,
    "next": 100,
    "data": [
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Traditionally, instance-based methods (memorybased learning) have been applied to a variety of NLP tasks (Daelemans and Van den Bosch, 2005), such as part of speech tagging (Daelemans et al., 1996), NER (Tjong Kim Sang, 2002; De Meulder and Daelemans, 2003; Hendrickx and van den Bosch, 2003), partial parsing (Daelemans et al."
            ],
            "citingPaper": {
                "paperId": "79b095a8a414ef041eebab0e8cd8705d74463a3d",
                "externalIds": {
                    "ArXiv": "2109.13497",
                    "DBLP": "journals/corr/abs-2109-13497",
                    "DOI": "10.1162/tacl_a_00439",
                    "CorpusId": 238198426
                },
                "url": "https://www.semanticscholar.org/paper/79b095a8a414ef041eebab0e8cd8705d74463a3d",
                "title": "Instance-Based Neural Dependency Parsing",
                "abstract": "Abstract Interpretable rationales for model predictions are crucial in practical applications. We develop neural models that possess an interpretable inference process for dependency parsing. Our models adopt instance-based inference, where dependency edges are extracted and labeled by comparing them to edges in a training set. The training edges are explicitly used for the predictions; thus, it is easy to grasp the contribution of each edge to the predictions. Our experiments show that our instance-based models achieve competitive accuracy with standard neural models and have the reasonable plausibility of instance-based explanations.",
                "venue": "Transactions of the Association for Computational Linguistics",
                "year": 2021,
                "referenceCount": 92,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "33516663",
                        "name": "Hiroki Ouchi"
                    },
                    {
                        "authorId": "153211541",
                        "name": "Jun Suzuki"
                    },
                    {
                        "authorId": "3456592",
                        "name": "Sosuke Kobayashi"
                    },
                    {
                        "authorId": "32286159",
                        "name": "Sho Yokoi"
                    },
                    {
                        "authorId": "83446147",
                        "name": "Tatsuki Kuribayashi"
                    },
                    {
                        "authorId": "2059965984",
                        "name": "Masashi Yoshikawa"
                    },
                    {
                        "authorId": "21773804",
                        "name": "Kentarou Inui"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Early work focused on machine translation (Sumita and Hitoshi, 1991), syntactic disambiguation (Cardie, 1994), and tagging (Daelemans, 1993; Daelemans et al., 1996)."
            ],
            "citingPaper": {
                "paperId": "8a99e1eb3285f127eed7169441679d47be7f1633",
                "externalIds": {
                    "ACL": "2021.emnlp-main.352",
                    "DBLP": "conf/emnlp/WisemanBS21",
                    "ArXiv": "2101.08248",
                    "DOI": "10.18653/v1/2021.emnlp-main.352",
                    "CorpusId": 237513517
                },
                "url": "https://www.semanticscholar.org/paper/8a99e1eb3285f127eed7169441679d47be7f1633",
                "title": "Data-to-text Generation by Splicing Together Nearest Neighbors",
                "abstract": "We propose to tackle data-to-text generation tasks by directly splicing together retrieved segments of text from \u201cneighbor\u201d source-target pairs. Unlike recent work that conditions on retrieved neighbors but generates text token-by-token, left-to-right, we learn a policy that directly manipulates segments of neighbor text, by inserting or replacing them in partially constructed generations. Standard techniques for training such a policy require an oracle derivation for each generation, and we prove that finding the shortest such derivation can be reduced to parsing under a particular weighted context-free grammar. We find that policies learned in this way perform on par with strong baselines in terms of automatic and human evaluation, but allow for more interpretable and controllable generation.",
                "venue": "EMNLP",
                "year": 2021,
                "referenceCount": 91,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2844243",
                        "name": "Sam Wiseman"
                    },
                    {
                        "authorId": "2064251",
                        "name": "A. Backurs"
                    },
                    {
                        "authorId": "1714215",
                        "name": "K. Stratos"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "91dda979e7dc7dc0aa1a858f990100897d5b2da4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2101-08248",
                    "CorpusId": 231647997
                },
                "url": "https://www.semanticscholar.org/paper/91dda979e7dc7dc0aa1a858f990100897d5b2da4",
                "title": "Generating (Formulaic) Text by Splicing Together Nearest Neighbors",
                "abstract": "We propose to tackle conditional text generation tasks, especially those which require generating formulaic text, by splicing together segments of text from retrieved \u201cneighbor\u201d source-target pairs. Unlike recent work that conditions on retrieved neighbors in an encoder-decoder setting but generates text token-by-token, left-to-right, we learn a policy that directly manipulates segments of neighbor text (i.e., by inserting or replacing them) to form an output. Standard techniques for training such a policy require an oracle derivation for each generation, and we prove that finding the shortest such derivation can be reduced to parsing under a particular weighted contextfree grammar. We find that policies learned in this way allow for interpretable table-to-text or headline generation that is competitive with neighbor-based token-level policies on automatic metrics, though on all but one dataset neighbor-based policies underperform a strong neighborless baseline. In all cases, however, generating by splicing is faster.",
                "venue": "ArXiv",
                "year": 2021,
                "referenceCount": 88,
                "citationCount": 1,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2844243",
                        "name": "Sam Wiseman"
                    },
                    {
                        "authorId": "2064251",
                        "name": "A. Backurs"
                    },
                    {
                        "authorId": "1714215",
                        "name": "K. Stratos"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "K-NN based approach in other NLP applications: Nearest neighbor models have been used in a number of NLP applications such as parts-of-speech tagging (Daelemans et al., 1996) and morphological analysis (Bosch et al., 2007).",
                "K-NN based approach in other NLP applications: Nearest neighbor models have been used in a number of NLP applications such as parts-of-speech tagging (Daelemans et al., 1996) and morphological analysis (Bosch et al."
            ],
            "citingPaper": {
                "paperId": "a07a94168608322600fd3cab54df1410b96852b6",
                "externalIds": {
                    "ArXiv": "2104.08762",
                    "DBLP": "conf/emnlp/DasZTGPLTPM21",
                    "ACL": "2021.emnlp-main.755",
                    "DOI": "10.18653/v1/2021.emnlp-main.755",
                    "CorpusId": 233296655
                },
                "url": "https://www.semanticscholar.org/paper/a07a94168608322600fd3cab54df1410b96852b6",
                "title": "Case-based Reasoning for Natural Language Queries over Knowledge Bases",
                "abstract": "It is often challenging to solve a complex problem from scratch, but much easier if we can access other similar problems with their solutions \u2014 a paradigm known as case-based reasoning (CBR). We propose a neuro-symbolic CBR approach (CBR-KBQA) for question answering over large knowledge bases. CBR-KBQA consists of a nonparametric memory that stores cases (question and logical forms) and a parametric model that can generate a logical form for a new question by retrieving cases that are relevant to it. On several KBQA datasets that contain complex questions, CBR-KBQA achieves competitive performance. For example, on the CWQ dataset, CBR-KBQA outperforms the current state of the art by 11% on accuracy. Furthermore, we show that CBR-KBQA is capable of using new cases without any further training: by incorporating a few human-labeled examples in the case memory, CBR-KBQA is able to successfully generate logical forms containing unseen KB entities as well as relations.",
                "venue": "EMNLP",
                "year": 2021,
                "referenceCount": 103,
                "citationCount": 19,
                "influentialCitationCount": 5,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "143863023",
                        "name": "R. Das"
                    },
                    {
                        "authorId": "1771307",
                        "name": "M. Zaheer"
                    },
                    {
                        "authorId": "2064894364",
                        "name": "Dung Ngoc Thai"
                    },
                    {
                        "authorId": "36851489",
                        "name": "Ameya Godbole"
                    },
                    {
                        "authorId": "3439053",
                        "name": "Ethan Perez"
                    },
                    {
                        "authorId": "1520031992",
                        "name": "Jay Yoon Lee"
                    },
                    {
                        "authorId": "2087344242",
                        "name": "Lizhen Tan"
                    },
                    {
                        "authorId": "1725498",
                        "name": "L. Polymenakos"
                    },
                    {
                        "authorId": "143753639",
                        "name": "A. McCallum"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "k-NN models have been employed for a number NLP tasks such as speech tagging (Daelemans et al., 1996), morphological analysis (Bosch et al., 2007), among many others.",
                "kNN models have been used for a number of NLP tasks such as part of speech tagging (Daelemans et al., 1996) and morphological analysis (Bosch et al."
            ],
            "citingPaper": {
                "paperId": "f980421e1ae7f2490f17157e29c5e2baff420cf0",
                "externalIds": {
                    "ArXiv": "2103.17055",
                    "DBLP": "journals/corr/abs-2103-17055",
                    "CorpusId": 232428158
                },
                "url": "https://www.semanticscholar.org/paper/f980421e1ae7f2490f17157e29c5e2baff420cf0",
                "title": "A Neighbourhood Framework for Resource-Lean Content Flagging",
                "abstract": "We propose a novel framework for cross-lingual content \ufb02agging with limited target-language data, which signi\ufb01cantly outperforms prior work in terms of predictive performance. The framework is based on a nearest-neighbour architecture. It is a modern instantiation of the vanilla k nearest neighbour model, as we use Transformer representations in all its compo-nents. Our framework can adapt to new source-language instances, without the need to be retrained from scratch. Unlike prior work on neighbourhood-based approaches, we encode the neighbourhood information based on query\u2013neighbour interactions. We propose two encoding schemes and we show their effectiveness using both qualitative and quantitative analysis. Our evaluation results on eight languages from two different datasets for abusive language detection show sizable improvements of up to 9.5 F1 points absolute (for Italian) over strong baselines. On average, we achieve 3.6 absolute F1 points of improvement for the three languages in the Jigsaw Multilingual dataset and 2.14 points for the WUL dataset.",
                "venue": "ArXiv",
                "year": 2021,
                "referenceCount": 75,
                "citationCount": 3,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science",
                    "Mathematics"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Mathematics",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2721029",
                        "name": "Sheikh Muhammad Sarwar"
                    },
                    {
                        "authorId": "46190940",
                        "name": "Dimitrina Zlatkova"
                    },
                    {
                        "authorId": "3255454",
                        "name": "Momchil Hardalov"
                    },
                    {
                        "authorId": "1379925776",
                        "name": "Yoan Dinkov"
                    },
                    {
                        "authorId": "1736067",
                        "name": "Isabelle Augenstein"
                    },
                    {
                        "authorId": "2026545715",
                        "name": "Preslav Nakov"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "\u2026the current neural era, instance-based learning, sometimes called memory-based learning (Daelemans and Van den Bosch, 2005), was widely used for various NLP tasks, such as part-of-speech tagging (Daelemans et al., 1996), dependency parsing (Nivre et al., 2004) and machine translation (Nagao, 1984).",
                "Before the current neural era, instance-based learning, sometimes called memory-based learning (Daelemans and Van den Bosch, 2005), was widely used for various NLP tasks, such as part-of-speech tagging (Daelemans et al., 1996), dependency parsing (Nivre et al."
            ],
            "citingPaper": {
                "paperId": "34b6dba255e98fdcddcc402f728df1be62e6fde0",
                "externalIds": {
                    "ArXiv": "2004.14514",
                    "MAG": "3022184516",
                    "DBLP": "journals/corr/abs-2004-14514",
                    "ACL": "2020.acl-main.575",
                    "DOI": "10.18653/v1/2020.acl-main.575",
                    "CorpusId": 216915281
                },
                "url": "https://www.semanticscholar.org/paper/34b6dba255e98fdcddcc402f728df1be62e6fde0",
                "title": "Instance-Based Learning of Span Representations: A Case Study through Named Entity Recognition",
                "abstract": "Interpretable rationales for model predictions play a critical role in practical applications. In this study, we develop models possessing interpretable inference process for structured prediction. Specifically, we present a method of instance-based learning that learns similarities between spans. At inference time, each span is assigned a class label based on its similar spans in the training set, where it is easy to understand how much each training instance contributes to the predictions. Through empirical analysis on named entity recognition, we demonstrate that our method enables to build models that have high interpretability without sacrificing performance.",
                "venue": "ACL",
                "year": 2020,
                "referenceCount": 50,
                "citationCount": 12,
                "influentialCitationCount": 2,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "33516663",
                        "name": "Hiroki Ouchi"
                    },
                    {
                        "authorId": "144042991",
                        "name": "Jun Suzuki"
                    },
                    {
                        "authorId": "3456592",
                        "name": "Sosuke Kobayashi"
                    },
                    {
                        "authorId": "32286159",
                        "name": "Sho Yokoi"
                    },
                    {
                        "authorId": "83446147",
                        "name": "Tatsuki Kuribayashi"
                    },
                    {
                        "authorId": "1666006598",
                        "name": "Ryuto Konno"
                    },
                    {
                        "authorId": "3040648",
                        "name": "Kentaro Inui"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "50f3357d324b79bb6679a828cc438df853a94334",
                "externalIds": {
                    "DBLP": "journals/csl/FerroBF20",
                    "MAG": "2973058042",
                    "DOI": "10.1016/j.csl.2019.101020",
                    "CorpusId": 203142023
                },
                "url": "https://www.semanticscholar.org/paper/50f3357d324b79bb6679a828cc438df853a94334",
                "title": "Adaptive scheduling for adaptive sampling in pos taggers construction",
                "abstract": null,
                "venue": "Comput. Speech Lang.",
                "year": 2020,
                "referenceCount": 60,
                "citationCount": 1,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1730828",
                        "name": "M. Ferro"
                    },
                    {
                        "authorId": "1805846",
                        "name": "V. Darriba"
                    },
                    {
                        "authorId": "3252869",
                        "name": "Jes\u00fas Vilares"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "K-NN based approach in other NLP applications: Nearest neighbor models have been applied to a number of NLP applications in the past such as parts-of-speech tagging [Daelemans et al., 1996] and morphological analysis [Bosch et al.",
                "K-NN based approach in other NLP applications: Nearest neighbor models have been applied to a number of NLP applications in the past such as parts-of-speech tagging [Daelemans et al., 1996] and morphological analysis [Bosch et al., 2007]."
            ],
            "citingPaper": {
                "paperId": "b7663a47f67d1a28908ecd3742dec3c254544ea1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2006-14198",
                    "MAG": "3029732686",
                    "ArXiv": "2006.14198",
                    "DOI": "10.24432/C52S3K",
                    "CorpusId": 219645319
                },
                "url": "https://www.semanticscholar.org/paper/b7663a47f67d1a28908ecd3742dec3c254544ea1",
                "title": "A Simple Approach to Case-Based Reasoning in Knowledge Bases",
                "abstract": "We present a surprisingly simple yet accurate approach to reasoning in knowledge graphs (KGs) that requires \\emph{no training}, and is reminiscent of case-based reasoning in classical artificial intelligence (AI). \nConsider the task of finding a target entity given a source entity and a binary relation. \nOur approach finds multiple \\textit{graph path patterns} that connect similar source entities through the given relation, and looks for pattern matches starting from the query source. \nUsing our method, we obtain new state-of-the-art accuracy, outperforming all previous models, on NELL-995 and FB-122. \nWe also demonstrate that our model is robust in low data settings, outperforming recently proposed meta-learning approaches.",
                "venue": "AKBC",
                "year": 2020,
                "referenceCount": 62,
                "citationCount": 8,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "143863023",
                        "name": "R. Das"
                    },
                    {
                        "authorId": "36851489",
                        "name": "Ameya Godbole"
                    },
                    {
                        "authorId": "3448411",
                        "name": "S. Dhuliawala"
                    },
                    {
                        "authorId": "1771307",
                        "name": "M. Zaheer"
                    },
                    {
                        "authorId": "143753639",
                        "name": "A. McCallum"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Nearest neighbor models have been applied to a number of NLP problems in the past, such as part of speech tagging (Daelemans et al., 1996) and morphological analysis (Bosch et al.",
                "Nearest neighbor models have been applied to a number of NLP problems in the past, such as part of speech tagging (Daelemans et al., 1996) and morphological analysis (Bosch et al., 2007), but the use of learned representations makes the similarity function much more effective in the case of neural\u2026"
            ],
            "citingPaper": {
                "paperId": "bb6317bbd2c4a81e94cf3d7eb1b73da246a022db",
                "externalIds": {
                    "MAG": "2995154514",
                    "DBLP": "conf/iclr/KhandelwalLJZL20",
                    "ArXiv": "1911.00172",
                    "CorpusId": 207870430
                },
                "url": "https://www.semanticscholar.org/paper/bb6317bbd2c4a81e94cf3d7eb1b73da246a022db",
                "title": "Generalization through Memorization: Nearest Neighbor Language Models",
                "abstract": "We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.",
                "venue": "ICLR",
                "year": 2019,
                "referenceCount": 32,
                "citationCount": 157,
                "influentialCitationCount": 18,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "3030219",
                        "name": "Urvashi Khandelwal"
                    },
                    {
                        "authorId": "39455775",
                        "name": "Omer Levy"
                    },
                    {
                        "authorId": "1746807",
                        "name": "Dan Jurafsky"
                    },
                    {
                        "authorId": "1982950",
                        "name": "Luke Zettlemoyer"
                    },
                    {
                        "authorId": "35084211",
                        "name": "M. Lewis"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "contexts": [
                "02% [4] For the abovementioned ten official languages, the results for most South African languages are still below the level of world leaders, boasting with accuracies of between 96% to 98% for Dutch, [5, 6] and English [7, 8] as examples.",
                "With part of speech tagger accuracies of between 82.08% and 96.02% [4] For the abovementioned ten official languages, the results for most South African languages are still below the level of world leaders, boasting with accuracies of between 96% to 98% for Dutch, [5, 6] and English [7, 8] as examples.",
                "1) MBT MBT (Memory-based tagger generation and tagging) [5] is based on TiMBL (Tilburg Memory-Based Learner) [12]."
            ],
            "citingPaper": {
                "paperId": "21d3eb97c02a7e8bba180181d79ca32c0336b9b8",
                "externalIds": {
                    "MAG": "3010217761",
                    "DOI": "10.1109/IMITEC45504.2019.9015872",
                    "CorpusId": 211686765
                },
                "url": "https://www.semanticscholar.org/paper/21d3eb97c02a7e8bba180181d79ca32c0336b9b8",
                "title": "A Combination Part of Speech Tagger using Selected Voting Methods",
                "abstract": "The development of resources in any language is an expensive process, many languages, including the indigenous languages of South Africa, can be classified as being resource scarce, or lacking in tagging resources. This study investigates and applies techniques and methodologies for optimising the use of available resources and improving the accuracy of a tagger using Afrikaans as resource-scarce language and aims to determine whether combination techniques can be effectively applied to improve the accuracy of a tagger for Afrikaans. In order to do this, existing methodologies for combining classification algorithms are investigated. Four taggers, trained using MBT, SVM1ight, MXPOST and TnT respectively, are then combined into a combination tagger using weighted voting. Weights are calculated by means of total precision, tag precision and a combination of precision and recall. Although the combination of taggers does not consistently lead to an error rate reduction with regard to the baseline, it manages to achieve an error rate reduction of up to 14.54% in some cases.",
                "venue": "2019 International Multidisciplinary Information Technology and Engineering Conference (IMITEC)",
                "year": 2019,
                "referenceCount": 27,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1516217510",
                        "name": "Annick Griebenouw"
                    },
                    {
                        "authorId": "2513661",
                        "name": "G. Drevin"
                    },
                    {
                        "authorId": "2088875",
                        "name": "Dirk P. Snyman"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "2be179312ab93158feed2795fab044d08432e6d8",
                "externalIds": {
                    "MAG": "2939173722",
                    "DOI": "10.13140/RG.2.2.31092.19849",
                    "CorpusId": 146010085
                },
                "url": "https://www.semanticscholar.org/paper/2be179312ab93158feed2795fab044d08432e6d8",
                "title": "An Online Syntactic and Semantic Framework for Lexical Relations Extraction Using Natural Language Deterministic Model",
                "abstract": "Given the extraordinary growth in online documents, methods for automated extraction of semantic relations became popular, and shortly after, became n",
                "venue": "",
                "year": 2019,
                "referenceCount": 194,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "46432268",
                        "name": "M. Ore\u0161kovi\u0107"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "4bdcda660e2e3f0dfdadbaa7ea922ec1bffeda2b",
                "externalIds": {
                    "MAG": "2805470984",
                    "DBLP": "journals/jois/KumarKS19",
                    "DOI": "10.1515/jisys-2017-0520",
                    "CorpusId": 65614962
                },
                "url": "https://www.semanticscholar.org/paper/4bdcda660e2e3f0dfdadbaa7ea922ec1bffeda2b",
                "title": "Deep Learning Based Part-of-Speech Tagging for Malayalam Twitter Data (Special Issue: Deep Learning Techniques for Natural Language Processing)",
                "abstract": "Abstract The paper addresses the problem of part-of-speech (POS) tagging for Malayalam tweets. The conversational style of posts/tweets/text in social media data poses a challenge in using general POS tagset for tagging the text. For the current work, a tagset was designed that contains 17 coarse tags and 9915 tweets were tagged manually for experiment and evaluation. The tagged data were evaluated using sequential deep learning methods like recurrent neural network (RNN), gated recurrent units (GRU), long short-term memory (LSTM), and bidirectional LSTM (BLSTM). The training of the model was performed on the tagged tweets, at word level and character level. The experiments were evaluated using measures like precision, recall, f1-measure, and accuracy. During the experiment, it was found that the GRU-based deep learning sequential model at word level gave the highest f1-measure of 0.9254; at character-level, the BLSTM-based deep learning sequential model gave the highest f1-measure of 0.8739. To choose the suitable number of hidden states, we varied it as 4, 16, 32, and 64, and performed training for each. It was observed that the increase in hidden states improved the tagger model. This is an initial work to perform Malayalam Twitter data POS tagging using deep learning sequential models.",
                "venue": "J. Intell. Syst.",
                "year": 2019,
                "referenceCount": 62,
                "citationCount": 10,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2109574495",
                        "name": "Sachin Kumar"
                    },
                    {
                        "authorId": "37874481",
                        "name": "M. A. Kumar"
                    },
                    {
                        "authorId": "144456263",
                        "name": "K. Soman"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "ad92d28648cd8136b3bbb888ee38d92845775d2e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1906-04225",
                    "MAG": "2953014395",
                    "ACL": "P19-1533",
                    "ArXiv": "1906.04225",
                    "DOI": "10.18653/v1/P19-1533",
                    "CorpusId": 184487062
                },
                "url": "https://www.semanticscholar.org/paper/ad92d28648cd8136b3bbb888ee38d92845775d2e",
                "title": "Label-Agnostic Sequence Labeling by Copying Nearest Neighbors",
                "abstract": "Retrieve-and-edit based approaches to structured prediction, where structures associated with retrieved neighbors are edited to form new structures, have recently attracted increased interest. However, much recent work merely conditions on retrieved structures (e.g., in a sequence-to-sequence framework), rather than explicitly manipulating them. We show we can perform accurate sequence labeling by explicitly (and only) copying labels from retrieved neighbors. Moreover, because this copying is label-agnostic, we can achieve impressive performance in zero-shot sequence-labeling tasks. We additionally consider a dynamic programming approach to sequence labeling in the presence of retrieved neighbors, which allows for controlling the number of distinct (copied) segments used to form a prediction, and leads to both more interpretable and accurate predictions.",
                "venue": "ACL",
                "year": 2019,
                "referenceCount": 34,
                "citationCount": 26,
                "influentialCitationCount": 1,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2844243",
                        "name": "Sam Wiseman"
                    },
                    {
                        "authorId": "1714215",
                        "name": "K. Stratos"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "e339b7e5740ac911c0e0ce754b844dbde840e060",
                "externalIds": {
                    "MAG": "2969303181",
                    "DOI": "10.1515/psicl-2019-0009",
                    "CorpusId": 201727507
                },
                "url": "https://www.semanticscholar.org/paper/e339b7e5740ac911c0e0ce754b844dbde840e060",
                "title": "Part of speech tagging for Polish",
                "abstract": "Abstract In this paper we discuss the current state of the art in part-of-speech tagging for Polish. We introduce the problem of POS tagging and point out the key issues in tagging inflected languages, which make this task more difficult in the case of Polish than e.g. English. We also discuss the most important language resources connected with POS tagging, as well as the task of morphological analysis, as it is commonly used as a preliminary step in tagging. We describe the methods that have been applied to the problem of POS tagging for Polish to date and discuss the most current, neural-network based methods in more detail. Finally, we conclude with a general view of this field in the context of Polish and discuss possible future research directions.",
                "venue": "Poznan Studies in Contemporary Linguistics",
                "year": 2019,
                "referenceCount": 64,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Psychology"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Psychology",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1411226796",
                        "name": "Katarzyna Krasnowska-Kieras"
                    },
                    {
                        "authorId": "70089109",
                        "name": "\u0141. Kobyli\u0144ski"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "contexts": [
                "eA memory-based part of speech tagger-generator by Reference [10].",
                "An example of an ME-based tagger is Stanford Log-Linear POS tagger implemented in Java by Reference [30].",
                "According to Reference [25], the MEMM-based tagger is introduced to provide a principled way of incorporating complex features into probability models.",
                "Related work of this kind has been reported in References [20] and [22].",
                "For example, in developing POS tagger for Assamese Text, an agglutinative Indic language, Reference [26] uses HMM and simple morphological analysis to determine probable tags for previously unseen words.",
                "Reference [8] use a morphological analyzer to improve the performance of the tagger for Bengali developed using HMM and MEMM.",
                "The full description of this tagset is given in Tables 11 and 12 of Appendix A. Refer to References [21, 23] for full details of the Igbo tagset and corpus developments.",
                "Also, Reference [14] revealed\nACM Trans.",
                "Reference [30] uses variable length suffixes up to a maximum length n for extracting word features such that n = 4 for ne\u0434otiable will generate [e,le,ble,able] feature list.",
                "The Tagged Igbo Corpora (IgbTC) was produced in Reference [21] using the tagset and corpus discussed in the section above.",
                "Apart from the obvious aim of developing a tagset that will capture the key linguistic features of the language, according to References [21] and [23], the tagset designed also focused on capturing the distinction between morphologically-inflected and non-inflected words, to facilitate subsequent investigation of Igbo morphology.",
                "This was originally developed by Reference [6] and subsequently improved both in speed and performance by References [15] and [19].",
                "CCS Concepts: \u2022 Computing methodologies\u2192 Natural language processing; Phonology / morphology; Supervised learning by classification;Rule learning;Ensemblemethods;Cross-validation; Language resources;\nAdditional Key Words and Phrases: Natural language processing (NLP), language technology, corpus annotation, part-of-speech (POS) tagging, POS tagger, text processing, African language, Igbo, corpora, morphological analysis, machine learning, tagset\nACM Reference format: Ikechukwu E. Onyenwe, Mark Hepple, Uchechukwu Chinedu, and Ignatius Ezeani.",
                "The lexicon is a list of 145 Igbo suffixeswe collected from the Igbo grammar book by Reference [12] and the Igbo corpus.",
                "Reference [10] introduced a memory-based supervised learning technique to POS tagging based on similarity reasoning.",
                "The Igbo corpus and tagset developed in the Reference [21] PhD research as part of the IgboNLP project has been used."
            ],
            "citingPaper": {
                "paperId": "fd5dea1d927d2b601a5a14b8582fdc23c649ef06",
                "externalIds": {
                    "MAG": "2946730224",
                    "DBLP": "journals/talip/OnyenweHUE19",
                    "DOI": "10.1145/3314942",
                    "CorpusId": 182924542
                },
                "url": "https://www.semanticscholar.org/paper/fd5dea1d927d2b601a5a14b8582fdc23c649ef06",
                "title": "Toward an Effective Igbo Part-of-Speech Tagger",
                "abstract": "Part-of-speech (POS) tagging is a well-established technology for most Western European languages and a few other world languages, but it has not been evaluated on Igbo, an agglutinative African language. This article presents POS tagging experiments conducted using an Igbo corpus as a test bed for identifying the POS taggers and the Machine Learning (ML) methods that can achieve a good performance with the small dataset available for the language. Experiments have been conducted using different well-known POS taggers developed for English or European languages, and different training data styles and sizes. Igbo has a number of language-specific characteristics that present a challenge for effective POS tagging. One interesting case is the wide use of verbs (and nominalizations thereof) that have an inherent noun complement, which form \u201clinked pairs\u201d in the POS tagging scheme, but which may appear discontinuously. Another issue is Igbo\u2019s highly productive agglutinative morphology, which can produce many variant word forms from a given root. This productivity is a key cause of the out-of-vocabulary (OOV) words observed during Igbo tagging. We report results of experiments on a promising direction for improving tagging performance on such morphologically-inflected OOV words.",
                "venue": "ACM Trans. Asian Low Resour. Lang. Inf. Process.",
                "year": 2019,
                "referenceCount": 50,
                "citationCount": 3,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "3452626",
                        "name": "I. Onyenwe"
                    },
                    {
                        "authorId": "2695497",
                        "name": "M. Hepple"
                    },
                    {
                        "authorId": "2148469404",
                        "name": "Uchechukwu Chinedu"
                    },
                    {
                        "authorId": "3452783",
                        "name": "I. Ezeani"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "\u2026tokenisation of the Tibetan text into\nsyllables, we used the Memory-Based Tagger generator (MBTg) based on the TiMBL software package designed by Daelemans et al. (1996).6 We chose MBT because it is freely available, easy to train on a new language and because we expected the model to behave\u2026"
            ],
            "citingPaper": {
                "paperId": "a098fece053d50890926af034b13471f4863cf75",
                "externalIds": {
                    "MAG": "2786173426",
                    "DOI": "10.5070/H916234501",
                    "CorpusId": 55651827
                },
                "url": "https://www.semanticscholar.org/paper/a098fece053d50890926af034b13471f4863cf75",
                "title": "Segmenting and POS tagging Classical Tibetan using a memory-based tagger",
                "abstract": "This paper presents a new approach to two challenging NLP tasks in Classical Tibetan: word segmentation and Part-of-Speech (POS) tagging. We demonstrate how both these problems can be approached in the same way, by generating a memory-based tagger that assigns 1) segmentation tags and 2) POS tags to a test corpus consisting of unsegmented lines of Tibetan characters. We propose a three-stage workflow and evaluate the results of both the segmenting and the POS tagging tasks. We argue that the Memory-Based Tagger (MBT) and the proposed workflow not only provide an adequate solution to these NLP challenges, they are also highly efficient tools for building larger annotated corpora of Tibetan.",
                "venue": "",
                "year": 2018,
                "referenceCount": 12,
                "citationCount": 8,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "73727229",
                        "name": "M. Meelen"
                    },
                    {
                        "authorId": "47932061",
                        "name": "N. Hill"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Por fim, PoS-tagger \u00e9 o processo no qual categorias sint\u00e1ticas s\u00e3o associadas \u00e0s palavras [4]."
            ],
            "citingPaper": {
                "paperId": "d4cd36bd3c8e197324acd393fa0ccfdd4c8d566b",
                "externalIds": {
                    "DBLP": "conf/webmedia/FerreiraC18",
                    "MAG": "2889858572",
                    "DOI": "10.1145/3243082.3267443",
                    "CorpusId": 52297988
                },
                "url": "https://www.semanticscholar.org/paper/d4cd36bd3c8e197324acd393fa0ccfdd4c8d566b",
                "title": "LISE - an automated analyser of business competitors",
                "abstract": "Nowadays, anyone with an initial idea can become an entrepreneur. But experts advise that the idea be well thought out before applying it to the market. The analysis of business competitors is one of the ways that helps the entrepreneur devise strategies to seize the market. However, the manual process of this review is time-consuming and tiring. Considering the great interaction of companies and their clients in social networks and Internet applications, this work presents LISE as a solution. This solution is a system developed to automate the process of analyzing competitors, using the application of Google Maps to collect data of the competitors of the locality that the entrepreneur wants to develop his company. As an expected contribution, this paper intends that this tool helps entrepreneurs to analyze their competitors quickly and easily.",
                "venue": "WebMedia",
                "year": 2018,
                "referenceCount": 34,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Business",
                        "source": "s2-fos-model"
                    },
                    {
                        "category": "Economics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2060141747",
                        "name": "Nayara da Silva Ferreira"
                    },
                    {
                        "authorId": "2058913730",
                        "name": "Val\u00e9ria Oliveira Costa"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "\u2022 Marsi [16] used a tag generator and memory-based tagger developed by Daelemans [17] to produce a tagger not for Arabic.",
                "[17] W. Daelemans, J. Zavrel, P. Berck, and S. Gillis, \u201cMBT: A MemoryBased Part of Speech Tagger-Generator,\u201d arXiv:cmp-lg/9607012, Jul. 1996."
            ],
            "citingPaper": {
                "paperId": "e71f7a6d42ce5323344f6c94fa0c2fd53b01fe7b",
                "externalIds": {
                    "MAG": "2800528265",
                    "DOI": "10.1109/ISACV.2018.8354032",
                    "CorpusId": 25758615
                },
                "url": "https://www.semanticscholar.org/paper/e71f7a6d42ce5323344f6c94fa0c2fd53b01fe7b",
                "title": "An hybrid approach to improve part of speech tagging system",
                "abstract": "Platforms interacting with data in text format, such as social networks or search engines, face major challenges regarding this flow of texts such as storage, search and information processing. New disciplines have emerged as natural language processing that involve identifying all aspects of language (spoken or written). In this perspective, we focus on the aspect of part-of speech (POS) tagging applied to the Arabic language which consists in marking each word in the text with its good tag. One of the most difficult problems affecting POS tagging is the ambiguity of the text. Ambiguity is the most important problem in the natural language processing. We propose a rule-based hybrid approach with an artificial neural network classifier to determine the appropriate tags of an Arabic text. The first phase consists of extracting all the affixes to identify the nature of the word and its tags according to grammatical rules, the second phase begins by transliterating the Arabic text into text with Roman letters. The transliterated text is then transformed into digital vectors to form the input of the classifier based on the neural networks. The two phases are combined to identify the tag of each word.",
                "venue": "2018 International Conference on Intelligent Systems and Computer Vision (ISCV)",
                "year": 2018,
                "referenceCount": 25,
                "citationCount": 2,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "34855816",
                        "name": "S. Farrah"
                    },
                    {
                        "authorId": "41033044",
                        "name": "Hanane El Manssouri"
                    },
                    {
                        "authorId": "50094336",
                        "name": "E. Ziyati"
                    },
                    {
                        "authorId": "2448996",
                        "name": "M. Ouzzif"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "\u0088 The baseline makes use of the automatic probabilistic chunker from the IXA-pipeline which provides Perceptron models (Collins, 2002) for chunking and is trained on CONLL2000 corpora and corrected manually, \u0088 DTSim uses a Conditional Random Field (CRF) based chunking tool using only POStags as features, \u0088 FBK-HLT-NLP obtains chunks using a Python implementation of MBSP chunker which uses a Memory-based part-of-speech tagger generator (Daelemans et al., 1996), \u0088 Run 1 of IISCNLP uses OpenNLP chunker which divides the sentence into syntactically correlated parts of words, but does not specify their internal structure, nor their role in the main sentence."
            ],
            "citingPaper": {
                "paperId": "038cd5aa9f80d2b103cd113bae5a23fee005306d",
                "externalIds": {
                    "MAG": "2923798796",
                    "CorpusId": 108342435
                },
                "url": "https://www.semanticscholar.org/paper/038cd5aa9f80d2b103cd113bae5a23fee005306d",
                "title": "Learning logic rules from text using statistical methods for natural language processing",
                "abstract": "The field of Natural Language Processing (NLP) examines how computers can be made to do beneficial tasks by understanding the natural language. The foundations of NLP are diverse and include scientific fields such as electrical and electronic engineering, linguistics, and artificial intelligence. Some popular NLP applications are information extraction, machine translation, text summarization, and question answering. This dissertation proposes a new methodology using Answer Set programming (ASP) as our main formalism to predict Interpretable Semantic Textual Similarity (iSTS) with a rule-based approach focusing on hard-coded rules for our system, Inspire. We next propose an intelligent rule learning methodology using Inductive Logic Programming (ILP) and modify the ILP-tool eXtended Hyrbid Abductive Inductive Learning (XHAIL) in order to test if we are able to learn the ASP-based rules that were hard-coded earlier on the chunking subtask of the Inspire system. Chunking is the identification of short phrases such as noun phrases which mainly rely on Part-of-Speech (POS) tags. We next evaluate our results using real data sets obtained from the SemEval2016 Task-2 iSTS competition to work with a real application which could be evaluated objectively using the test-sets provided by experts. The Inspire system participated at the SemEval2016 Task-2 iSTS competition in the subtasks of predicting chunk similarity alignments for gold chunks and system generated chunks for three different Datasets. The Inspire system extended the basic ideas from SemEval2015 iSTS Task participant NeRoSim, by realising the rules in logic programming and obtaining the result with an Answer Set Solver. To prepare the input for the logic program, the PunktTokenizer, Word2Vec, and WordNet APIs of NLTK, and the Part-of-Speech (POS) and Named-Entity-Recognition (NER) taggers from Stanford CoreNLP were used. For the chunking subtask, a joint POS-tagger and dependency parser were used based on which an Answer Set program determined chunks. The Inspire system ranked third place overall and first place in one of the competition datasets in the gold chunk subtask. For the above mentioned system, we decided to automate the sentence chunking process by learning the ASP rules using a statistical logical method which combines rule-based and statistical artificial intelligence methods, namely ILP. ILP has been applied to a variety of NLP problems some of which include parsing, information extraction, and question answering. XHAIL, is the ILP-tool we used that aims at generating a hypothesis, which is a logic program, from given background knowledge and examples of structured knowledge based on information provided by the POS-tags One of the main challenges was to extend the XHAIL algorithm for ILP which is based on ASP. With respect to processing natural language, ILP can cater for the constant change in how language is used on a daily basis. At the same time, ILP does not require huge amounts of training examples such as other statistical methods and produces interpretable results, that means a set of rules, which can be analysed and tweaked if necessary. As contributions XHAIL was extended with (i) a pruning mechanism within the hypothesis generalisation algorithm which enables learning from larger datasets, (ii) a better usage of modern solver technology using recently developed optimisation methods, and (iii) a time budget that permits the usage of suboptimal results. These improvements were evaluated on the subtask of sentence chunking using the same three datasets obtained from the SemEval2016 Task-2 competition. Results show that these improvements allow for learning on bigger datasets with results that are of similar quality to state-of-the-art systems on the same task. Moreover, the hypotheses obtained from individual datasets were compared to each other to gain insights on the structure of each dataset. Using ILP to extend our Inspire system not only automates the process of chunking the sentences but also provides us with interpretable models that are useful for providing a deeper understanding of the data being used and how it can be manipulated, which is a feature that is absent in popular Machine Learning methods.",
                "venue": "",
                "year": 2017,
                "referenceCount": 66,
                "citationCount": 1,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1867770",
                        "name": "Mishal Kazmi"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "contexts": [
                "2 million tokens, 50000 sentences, and 57962 word types (containing 13% ambiguous types and 76% ambiguous tokens) (Brants, 2000b; Daelemans et al., 1996; Toutanova et al., 2003; Hal\u00e1csy et al., 2007), while Hungarian corpus contains 1161015 tokens and 70083 sentences (Hal\u00e1csy et al.",
                "\u2022 Memory-Based Tagger MBT (Daelemans et al., 1996) uses feature patterns defined to add extra information to the tagger concerning the contextual information and the formation of the words to be tagged.",
                "Brill\u2019s TBL Brill (1995a) reimplemented by (Ngai and Florian, 2001) A memory-based part of speech tagger-generator by (Daelemans et al., 1996) Tilburg Memory-Based Learner",
                ", 2003), MBT\u2013 A memory-based POS tagger-generator by Daelemans et al. (1996), and FnTBL\u2013 Transformation-based learning in the fast lane by Ngai and Florian (2001) for this experiment.",
                "Daelemans et al. (1996) introduce a memory-based supervised learning techniques to POS tagging based on similarity reasoning."
            ],
            "citingPaper": {
                "paperId": "2e75c5eb44a0084d2b5c7c4d4880596e0e9b3a6a",
                "externalIds": {
                    "DBLP": "phd/ethos/Onyenwe17",
                    "MAG": "2619358065",
                    "CorpusId": 52882443
                },
                "url": "https://www.semanticscholar.org/paper/2e75c5eb44a0084d2b5c7c4d4880596e0e9b3a6a",
                "title": "Developing methods and resources for automated processing of the African language Igbo",
                "abstract": "Natural Language Processing (NLP) research is still in its infancy in Africa. Most of \nlanguages in Africa have few or zero NLP resources available, of which Igbo is among those \nat zero state. In this study, we develop NLP resources to support NLP-based research in \nthe Igbo language. The springboard is the development of a new part-of-speech (POS) \ntagset for Igbo (IgbTS) based on a slight adaptation of the EAGLES guideline as a result \nof language internal features not recognized in EAGLES. The tagset consists of three \ngranularities: fine-grain (85 tags), medium-grain (70 tags) and coarse-grain (15 tags). The \nmedium-grained tagset is to strike a balance between the other two grains for practical \npurpose. Following this is the preprocessing of Igbo electronic texts through normalization \nand tokenization processes. The tokenizer is developed in this study using the tagset \ndefinition of a word token and the outcome is an Igbo corpus (IgbC) of about one million \ntokens. \nThis IgbTS was applied to a part of the IgbC to produce the first Igbo tagged corpus \n(IgbTC). To investigate the effectiveness, validity and reproducibility of the IgbTS, an \ninter-annotation agreement (IAA) exercise was undertaken, which led to the revision of the \nIgbTS where necessary. A novel automatic method was developed to bootstrap a manual \nannotation process through exploitation of the by-products of this IAA exercise, to improve \nIgbTC. To further improve the quality of the IgbTC, a committee of taggers approach \nwas adopted to propose erroneous instances on IgbTC for correction. A novel automatic \nmethod that uses knowledge of affixes to flag and correct all morphologically-inflected \nwords in the IgbTC whose tags violate their status as not being morphologically-inflected \nwas also developed and used. \nExperiments towards the development of an automatic POS tagging system for Igbo \nusing IgbTC show good accuracy scores comparable to other languages that these taggers \nhave been tested on, such as English. Accuracy on the words previously unseen during \nthe taggers\u2019 training (also called unknown words) is considerably low, and much lower \non the unknown words that are morphologically-complex, which indicates difficulty in \nhandling morphologically-complex words in Igbo. This was improved by adopting a \nmorphological reconstruction method (a linguistically-informed segmentation into stems \nand affixes) that reformatted these morphologically-complex words into patterns learnable \nby machines. This enables taggers to use the knowledge of stems and associated affixes \nof these morphologically-complex words during the tagging process to predict their \nappropriate tags. Interestingly, this method outperforms other methods that existing \ntaggers use in handling unknown words, and achieves an impressive increase for the \naccuracy of the morphologically-inflected unknown words and overall unknown words. \nThese developments are the first NLP toolkit for the Igbo language and a step towards \nachieving the objective of Basic Language Resources Kits (BLARK) for the language. This \nIgboNLP toolkit will be made available for the NLP community and should encourage \nfurther research and development for the language.",
                "venue": "",
                "year": 2017,
                "referenceCount": 111,
                "citationCount": 8,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "3452626",
                        "name": "I. Onyenwe"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "\u2026as features,\n\u2022 FBK-HLT-NLP obtains chunks using a Python implementation of MBSP chunker which uses a Memory-based part-of-speech tagger generator (Daelemans et al., 1996),\n\u2022 Run 1 of IISCNLP uses OpenNLP chunker which divides the sentence into syntactically correlated parts of words, but\u2026",
                "\u2022 FBK-HLT-NLP obtains chunks using a Python implementation of MBSP chunker which uses a Memory-based part-of-speech tagger generator (Daelemans et al., 1996),"
            ],
            "citingPaper": {
                "paperId": "32d371b40a5f42911daaf634c269ab67fe126f45",
                "externalIds": {
                    "MAG": "2626901752",
                    "DBLP": "journals/eswa/KazmiSS17",
                    "ArXiv": "1706.05171",
                    "DOI": "10.1016/j.eswa.2017.06.013",
                    "CorpusId": 10067526
                },
                "url": "https://www.semanticscholar.org/paper/32d371b40a5f42911daaf634c269ab67fe126f45",
                "title": "Improving scalability of inductive logic programming via pruning and best-effort optimisation",
                "abstract": null,
                "venue": "Expert Syst. Appl.",
                "year": 2017,
                "referenceCount": 72,
                "citationCount": 15,
                "influentialCitationCount": 3,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1867770",
                        "name": "Mishal Kazmi"
                    },
                    {
                        "authorId": "1777794",
                        "name": "P. Sch\u00fcller"
                    },
                    {
                        "authorId": "1793443",
                        "name": "Y. Saygin"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "8b405ce88536a94c33e87ad346bb585a7d7f7183",
                "externalIds": {
                    "DBLP": "conf/nodalida/HohleOV17",
                    "ACL": "W17-0217",
                    "MAG": "2582133128",
                    "CorpusId": 26887225
                },
                "url": "https://www.semanticscholar.org/paper/8b405ce88536a94c33e87ad346bb585a7d7f7183",
                "title": "Optimizing a PoS Tagset for Norwegian Dependency Parsing",
                "abstract": "This paper reports on a suite of experiments that evaluates how the linguistic granularity of part-of-speech tagsets impacts the performance of tagging and syntactic dependency parsing. Our results show that parsing accuracy can be significantly improved by introducing more finegrained morphological information in the tagset, even if tagger accuracy is compromised. Our taggers and parsers are trained and tested using the annotations of the Norwegian Dependency Treebank.",
                "venue": "NODALIDA",
                "year": 2017,
                "referenceCount": 58,
                "citationCount": 4,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "47691315",
                        "name": "Petter Hohle"
                    },
                    {
                        "authorId": "2732223",
                        "name": "Lilja \u00d8vrelid"
                    },
                    {
                        "authorId": "2027091",
                        "name": "Erik Velldal"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "bba8888070434547dc3e62c49c7476a36c52c38b",
                "externalIds": {
                    "MAG": "2615493781",
                    "DOI": "10.5433/2237-4876.2017V20N1P218",
                    "CorpusId": 148743237
                },
                "url": "https://www.semanticscholar.org/paper/bba8888070434547dc3e62c49c7476a36c52c38b",
                "title": "Densidade lexical na escrita de textos escolares",
                "abstract": "This article presents a correlational study between lexical density and school progression in texts written by school age children and adolescents, monolingual speakers of European Portuguese. The measure used to assess lexical density is the ratio of lexical words to the total number of words (global density), as proposed by Ure (1971). This measure is complemented by the ratio of specific word classes (name, verb, adjective and adverb) to the total number of words. Using IMS Open Corpus Workbench tool, this measures was extracted from a quasi -longitudinal corpus consisting of 244 texts of narrative (n = 122) and argumentative (n = 122) register, written by students in the 5 th (n = 26), the 7 th (n = 46) and 10 th (n = 50) year of the Portuguese basic schooling system. The results show that there are no correlations between global lexical density and school progression in both registers. Regarding specific lexical density, it was found that, in one hand, there is a positive correlation between nominal density and progression and, on the other hand, there is a negative correlation between verbal density and progression. This work aims to contribute to a more detailed understanding of the lexical development of children and adolescents written language across school progression.",
                "venue": "",
                "year": 2017,
                "referenceCount": 19,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Psychology"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Psychology",
                        "source": "external"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "120783072",
                        "name": "M\u00e1rio Martins"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "be67b1fc82f3aab6cd99b6297c8375e7cb1f3ae2",
                "externalIds": {
                    "DBLP": "conf/bdca/AmriZO17",
                    "MAG": "2741257668",
                    "DOI": "10.1145/3090354.3090362",
                    "CorpusId": 7664935
                },
                "url": "https://www.semanticscholar.org/paper/be67b1fc82f3aab6cd99b6297c8375e7cb1f3ae2",
                "title": "Build a Morphosyntaxically Annotated Amazigh Corpus",
                "abstract": "Language resources are important for those working on computational methods to analyze and study languages. These resources are needed to help advancing the research in fields such as natural language processing, machine learning, information retrieval and text analysis in general. We describe the creation of morphosyntactically annotated corpus for Amazigh language that currently lacks them. We illustrate our approach for creating this corpus, that is more expensive but of high quality, using crowdsourcing and manual effort with appropriately skilled human participants. Qualitative and quantitative evaluations of the resources are also presented.",
                "venue": "BDCA'17",
                "year": 2017,
                "referenceCount": 58,
                "citationCount": 4,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "35368359",
                        "name": "S. Amri"
                    },
                    {
                        "authorId": "2909419",
                        "name": "L. Zenkouar"
                    },
                    {
                        "authorId": "2444746",
                        "name": "M. Outahajala"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "f28eff03f7ef97cfbffb8d6e4b846e97be278251",
                "externalIds": {
                    "DBLP": "journals/csl/FerroBR17",
                    "MAG": "2423413767",
                    "DOI": "10.1016/j.csl.2016.06.001",
                    "CorpusId": 44488581
                },
                "url": "https://www.semanticscholar.org/paper/f28eff03f7ef97cfbffb8d6e4b846e97be278251",
                "title": "Modeling of learning curves with applications to POS tagging",
                "abstract": null,
                "venue": "Comput. Speech Lang.",
                "year": 2017,
                "referenceCount": 99,
                "citationCount": 6,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1730828",
                        "name": "M. Ferro"
                    },
                    {
                        "authorId": "1805846",
                        "name": "V. Darriba"
                    },
                    {
                        "authorId": "1770533",
                        "name": "F. J. Ribadas"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "The particular machine learning approach to part-of-speech tagging adopted for TTNWW, MBT (memorybased tagger), was originally introduced by Daelemans et al. (1996)."
            ],
            "citingPaper": {
                "paperId": "ff26f7d9dea9055ded4ac6dfe79c3b15de913270",
                "externalIds": {
                    "MAG": "2775762559",
                    "DOI": "10.5334/BBI.7",
                    "CorpusId": 4246296
                },
                "url": "https://www.semanticscholar.org/paper/ff26f7d9dea9055ded4ac6dfe79c3b15de913270",
                "title": "TTNWW to the rescue: no need to know how to handle tools and resources",
                "abstract": "\"But I don\u2019t know how to work with [name of tool or resource]\" is something one often hears when researchers in Human and Social Sciences (HSS) are confronted with language technology, be it written or spoken, tools or resources. The TTNWW project shows that these researchers do not need to be experts in language or speech technology, or to know all kinds of details about the tools involved. In principle they only need to make clear what they want to achieve. In this paper we describe a series of tools that are already available as a webservice. Details are not presented - interested readers are referred to the papers mentioned in the References and to the TTNWW website.",
                "venue": "",
                "year": 2017,
                "referenceCount": 48,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Education",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1403936083",
                        "name": "M. Kemps-Snijders"
                    },
                    {
                        "authorId": "1781666",
                        "name": "I. Schuurman"
                    },
                    {
                        "authorId": "1735272",
                        "name": "Walter Daelemans"
                    },
                    {
                        "authorId": "1719822",
                        "name": "Kris Demuynck"
                    },
                    {
                        "authorId": "1806059",
                        "name": "Brecht Desplanques"
                    },
                    {
                        "authorId": "2653729",
                        "name": "Veronique Hoste"
                    },
                    {
                        "authorId": "2028879",
                        "name": "Marijn Huijbregts"
                    },
                    {
                        "authorId": "144400814",
                        "name": "J. Martens"
                    },
                    {
                        "authorId": "3089779",
                        "name": "Hans Paulussen"
                    },
                    {
                        "authorId": "2277087",
                        "name": "Joris Pelemans"
                    },
                    {
                        "authorId": "2777127",
                        "name": "Martin Reynaert"
                    },
                    {
                        "authorId": "1757713",
                        "name": "Vincent Vandeghinste"
                    },
                    {
                        "authorId": "145977875",
                        "name": "Antal van den Bosch"
                    },
                    {
                        "authorId": "3271841",
                        "name": "H. V. D. Heuvel"
                    },
                    {
                        "authorId": "3218618",
                        "name": "M. V. Gompel"
                    },
                    {
                        "authorId": "143715131",
                        "name": "Gertjan van Noord"
                    },
                    {
                        "authorId": "144969384",
                        "name": "P. Wambacq"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "009e0c594ec43f782d4807588539b5ba43cb76a6",
                "externalIds": {
                    "CorpusId": 36541112
                },
                "url": "https://www.semanticscholar.org/paper/009e0c594ec43f782d4807588539b5ba43cb76a6",
                "title": "ACL-COLING 1998 , Montreal , Canada , 491-497 , 1998 Improving Data",
                "abstract": "In this paper we examine how the di erences in modelling between di erent data driven systems performing the same NLP task can be exploited to yield a higher accuracy than the best indi vidual system We do this by means of an ex periment involving the task of morpho syntactic wordclass tagging Four well known tagger gen erators Hidden Markov Model Memory Based Transformation Rules and Maximum Entropy are trained on the same corpus data Af ter comparison their outputs are combined us ing several voting strategies and second stage classi ers All combination taggers outperform their best component with the best combina tion showing a lower error rate than the best individual tagger",
                "venue": "",
                "year": 2016,
                "referenceCount": 13,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2165139",
                        "name": "H. V. Halteren"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "For the part of speech tagging, the memory-based tagger MBT (Daelemans et al., 1996), trained on the Wall Street Journal corpus2, was used."
            ],
            "citingPaper": {
                "paperId": "031a59a3f5bc8fe7175b182b8d1180d35333c5a1",
                "externalIds": {
                    "CorpusId": 4185356
                },
                "url": "https://www.semanticscholar.org/paper/031a59a3f5bc8fe7175b182b8d1180d35333c5a1",
                "title": "Evaluating the results of a memory",
                "abstract": "In this paper, we evaluate the results of the Antwerp University word sense disambiguation system in the English all words task of SENSEVAL-2. In this approach, specialized memory-based wordexperts were trained per word-POS combination. Through optimization by crossvalidation of the individual component classifiers and the voting scheme for combining them, the best possible word-expert was determined. In the competition, this word-expert architecture resulted in accuracies of 63.6% (fine-grained) and 64.5% (coarse-grained) on the SENSEVAL-2 test data. In order to better understand these results, we investigated whether classifiers trained on different information sources performed differently on the different part-of-speech categories. Furthermore, the results were evaluated in terms of the available number of training items, the number of senses, and the sense distributions in the data set. We conclude that there is no information source which is optimal over all word-experts. Selecting the optimal classifier/voter for each single word-expert, however, leads to major accuracy improvements. We furthermore show that accuracies do not so much depend on the available number of training items, but largely on polysemy and sense distributions.",
                "venue": "",
                "year": 2016,
                "referenceCount": 16,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2653729",
                        "name": "Veronique Hoste"
                    },
                    {
                        "authorId": "1735272",
                        "name": "Walter Daelemans"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [
                "In [16], [17], [18] discusses hidden markov model based POS tagging, memory based learning [19], maximum entropy modeling [20], transformation based learning [21], decision trees [22], [23], support vector machines [24], [13], rule based approach [25], using disambiguation rule [26], [27], hybrid approaches are also been made using stochastic method and rules [28]."
            ],
            "citingPaper": {
                "paperId": "081b25209172b0e11e527d683ecd8b06474dcc05",
                "externalIds": {
                    "MAG": "2518219968",
                    "CorpusId": 40129549
                },
                "url": "https://www.semanticscholar.org/paper/081b25209172b0e11e527d683ecd8b06474dcc05",
                "title": "Experimental analysis of malayalam pos tagger using epic framework in scala",
                "abstract": "In Natural Language Processing (NLP), one of the well-studiedproblems under constant exploration is part-ofspeech tagging or POS tagging or grammatical tagging. The task is to assign labels or syntactic categories such as noun, verb, adjective, adverb, preposition etc. to the words in a sentence or in an un-annotated corpus. This paper presents a simple machine learning based experimental study for POS tagging using a new structured prediction framework known as EPIC, developed in scale programming language. This paper is first of its kind to perform POS tagging in Indian Language using EPIC framework. In this framework, the corpus contains labelled Malayalam sentences in domains like health, tourism and general (news, stories). The EPIC framework uses conditional random field (CRF) for building tagged models. The framework provides several parameters to adjust and arrive at improved accuracy and thereby a better POS tagger model. The overall accuracy were calculated separately for each domains and obtained a maximum accuracy of 85.48%, 85.39%, and 87.35% for small tagged data in health, tourism and general domain.",
                "venue": "",
                "year": 2016,
                "referenceCount": 35,
                "citationCount": 3,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Engineering"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Engineering",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2109574495",
                        "name": "Sachin Kumar"
                    },
                    {
                        "authorId": "37874481",
                        "name": "M. A. Kumar"
                    },
                    {
                        "authorId": "144456263",
                        "name": "K. Soman"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "95 Os etiquetadores podem ser constru\u00eddos (i) baseados em regras [18], restri\u00e7\u00f5es [19], casos [20] e em \u00e1rvores de decis\u00f5es n\u00e3o probabil\u00edsticas, denominados simb\u00f3licos, (ii) baseados em modelos probabil\u00edsticos [21] podendo utilizar de redes neurais [22], m\u00e1xima entropia [23], Modelo de Markov [24] e \u00e1rvores de decis\u00e3o probabil\u00edsticas [21] para calcular qual a probabilidade de determinada palavra receber a etiqueta com seu respectivo contexto, denominado estoc\u00e1sticos, ou (iii) h\u00edbridos, que s\u00e3o baseados na combina\u00e7\u00e3o dos dois modelos apresentados anteriormente, ou seja, o processo de etiquetagem deste modelo emprega tanto os modelos baseados em regras quanto os modelos estoc\u00e1sticos."
            ],
            "citingPaper": {
                "paperId": "2cd451aadbab7f57c1a0117d78d86b5e71868d96",
                "externalIds": {
                    "MAG": "2560473444",
                    "DOI": "10.5753/RBIE.2016.24.02.92",
                    "CorpusId": 64013117
                },
                "url": "https://www.semanticscholar.org/paper/2cd451aadbab7f57c1a0117d78d86b5e71868d96",
                "title": "Lexical-Syntactic Evaluation of written activities based on Genetic Algorithm and Natural Language Processing: An experiment on ENEM",
                "abstract": "The use of information and communication technologies is increasingly standing out in Education. Currently, there are several technologies that provide support for distance learning. Before this scenario, there are millions of users with an huge amount of educational data, which evaluation burdens teachers and consume their time, leaving the students waiting for the evaluation of their performance. With the use of automatic correction technics performed by computers, there is a bigger fluidity of activities and a relevant decrease of work for the teachers, leaving them free to evaluate others activities. This paper presents a lexical-Syntactic Analyzer for automatic evaluation of written Activities in Portuguese using Genetic Algorithms and Natural Language Processing \u2013 NLP. The proposed system was evaluated by experiment, about 20 written activities and it found and evaluated the mistakes previously identified by human correctors. The results demonstrated a high rate of appropriate suggestions for the errors detected.",
                "venue": "",
                "year": 2016,
                "referenceCount": 46,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "31134378",
                        "name": "J\u00e1rio Santos"
                    },
                    {
                        "authorId": "33961712",
                        "name": "R. Paiva"
                    },
                    {
                        "authorId": "2321725",
                        "name": "I. Bittencourt"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "5352dbeeb8c5e3627371cdab8da23334983db8ae",
                "externalIds": {
                    "MAG": "2527868884",
                    "DOI": "10.15368/THESES.2016.118",
                    "CorpusId": 64270650
                },
                "url": "https://www.semanticscholar.org/paper/5352dbeeb8c5e3627371cdab8da23334983db8ae",
                "title": "WHISK: Web Hosted Information into Summarized Knowledge",
                "abstract": "WHISK: Web Hosted Information into Summarized Knowledge",
                "venue": "",
                "year": 2016,
                "referenceCount": 75,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "39365627",
                        "name": "Jiewen Wu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Turning to statistical and machine learning approaches for POS tagging, these methods can be listed as various Markov Models-based methods [37, 65, 9, 25, 19], maximum entropy-based methods [50, 66, 67, 69, 11], perceptron algorithm-based approaches [12, 59, 63], hybrid methods [26, 18], and other machine learning-based approaches including neural networks [54], decision trees [55], finite-state transducers [52], memory-based learning [14], Support Vector Machines [24] and Conditional Random Fields [32, 33, 39]."
            ],
            "citingPaper": {
                "paperId": "58a8cf3f491b7a53b277947253356578167198e8",
                "externalIds": {
                    "DBLP": "journals/aicom/NguyenNPP15",
                    "ArXiv": "1412.4021",
                    "MAG": "1933786044",
                    "DOI": "10.3233/AIC-150698",
                    "CorpusId": 17107183
                },
                "url": "https://www.semanticscholar.org/paper/58a8cf3f491b7a53b277947253356578167198e8",
                "title": "A Robust Transformation-Based Learning Approach Using Ripple Down Rules for Part-Of-Speech Tagging",
                "abstract": "In this paper, we propose a new approach to construct a system of transformation rules for the Part-of-Speech (POS) tagging task. Our approach is based on an incremental knowledge acquisition method where rules are stored in an exception structure and new rules are only added to correct the errors of existing rules; thus allowing systematic control of the interaction between the rules. Experimental results on 13 languages show that our approach is fast in terms of training time and tagging speed. Furthermore, our approach obtains very competitive accuracy in comparison to state-of-the-art POS and morphological taggers.",
                "venue": "AI Commun.",
                "year": 2014,
                "referenceCount": 103,
                "citationCount": 39,
                "influentialCitationCount": 1,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "34691913",
                        "name": "Dat Quoc Nguyen"
                    },
                    {
                        "authorId": "38798269",
                        "name": "D. Q. Nguyen"
                    },
                    {
                        "authorId": "1781794",
                        "name": "Dang Duc Pham"
                    },
                    {
                        "authorId": "1798689",
                        "name": "S. Pham"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "reference points: Decision-trees [5], [48]; Neural Networks [15], [6]; Bayesian Nets [38]; Case-Based [19], Inductive Logic Programming [17]; Support Vector Machine [29] etc.",
                "However, for the interested reader we provide some\nreference points: Decision-trees [5], [48]; Neural Networks [15], [6]; Bayesian Nets [38]; Case-Based [19], Inductive Logic Programming [17]; Support Vector Machine [29] etc."
            ],
            "citingPaper": {
                "paperId": "8e355ffd77f475a5dfe58cf4d24f3c2fb7a5b2f1",
                "externalIds": {
                    "CorpusId": 12098761
                },
                "url": "https://www.semanticscholar.org/paper/8e355ffd77f475a5dfe58cf4d24f3c2fb7a5b2f1",
                "title": "An Overview of Data-Driven Part-of-Speech Tagging",
                "abstract": "Over the last twenty years or so, the approaches to partof-speech tagging based on machine learning techniques have been developed or ported to provide high-accuracy morpho-lexical annotation for an increasing number of languages. Given the large number of morpho-lexical descriptors for a morphologically complex language, one has to consider ways to avoid the data sparseness threat in standard statistical tagging, yet to ensure that the full lexicon information is available for each wordform in the output. The paper overviews some of the major approaches to part-of-speech tagging and touches upon the tagset design, which is of crucial importance for the accuracy of the process. Key-words: ambiguity class, data sparseness, lexical ambiguity, machine learning, multilinguality, part-of-speech tagging, tagset design.",
                "venue": "",
                "year": 2016,
                "referenceCount": 58,
                "citationCount": 1,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1693993",
                        "name": "D. Tufis"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "The widely known types of these approaches are divided into: Rule-Based, Probability-Based and Memory-Based approaches [31, 32]."
            ],
            "citingPaper": {
                "paperId": "a0c926a7d5b9b071f9bc1685eddcf6344b19c1af",
                "externalIds": {
                    "MAG": "2581081811",
                    "DOI": "10.11648/J.IJIIS.20160506.11",
                    "CorpusId": 38583861
                },
                "url": "https://www.semanticscholar.org/paper/a0c926a7d5b9b071f9bc1685eddcf6344b19c1af",
                "title": "Using Text's Terms and Syntactical Properties for Document Similarity",
                "abstract": "This paper reports on experiments performed to investigate the use of syntactical structures of sentences combined with sentences' terms for document similarity calculation. The document's sentences were first converted into ordered Part of Speech (POS) tags that were then fed into the Longest Common Subsequence (LCS) algorithm to determine the size and count of the LCSs found when comparing the document sentence by sentence. As a first stage, these syntactical features of the text were used as a structural representation of the document\u2019s text. However, the produced strings of tags not only work as text representative but also provide for text size reduction. This improves the processing efficiency of comparing the document's representative strings using the LCS. A score is generated by computing an accumulative value based on the number of the LCSs found. In the second stage, documents that score well in the first stage are subjected to further comparison using the actual words of the sentences (content) in a sentence by sentence fashion. An overall final is generated as a measure of similarity using the common words (accumulated for the whole document) and the total number of LCSs from the first step. Experiments were done on two different corpora. Results obtained have showed the utility of the proposed procedure in calculating similarities between written documents. The overall discrimination power was maintained while the size of the documents was reduced using only a representative of the document based on the tagged string.",
                "venue": "",
                "year": 2016,
                "referenceCount": 41,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1867985",
                        "name": "M. Elhadi"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "a178435660da68f9bc0e1c7cfddbc6fba72e2670",
                "externalIds": {
                    "MAG": "2519374477",
                    "CorpusId": 99787575
                },
                "url": "https://www.semanticscholar.org/paper/a178435660da68f9bc0e1c7cfddbc6fba72e2670",
                "title": "A DIV E RS ID ADE L E XI C AL NA E S C RI TA DE TE XTO S E S C OL A R E S",
                "abstract": null,
                "venue": "",
                "year": 2016,
                "referenceCount": 25,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Physics"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Physics",
                        "source": "external"
                    }
                ],
                "authors": [
                    {
                        "authorId": "120783072",
                        "name": "M\u00e1rio Martins"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Other notable approaches in POS tagging are Brill\u2019s transformation-based learning paradigm [27], the memorybased tagging paradigm [28], and the maximum entropy-based approach [29]."
            ],
            "citingPaper": {
                "paperId": "a1c9a6bd5ea21d722422076895373b7837d54819",
                "externalIds": {
                    "MAG": "2564858777",
                    "CorpusId": 54829589
                },
                "url": "https://www.semanticscholar.org/paper/a1c9a6bd5ea21d722422076895373b7837d54819",
                "title": "A free/open-source hybrid morphological disambiguation tool for Kazakh",
                "abstract": "This paper presents the results of developing a morphological disambiguation tool for Kazakh. Starting with a previously developed rule-based approach, we tried to cope with the complex morphology of Kazakh by breaking up lexical forms across their derivational boundaries into inflectional groups and modeling their behavior with statistical methods. A hybrid rule-based/statistical approach appears to benefit morphological disambiguation demonstrating a per-token accuracy of 91% in running text.",
                "venue": "",
                "year": 2016,
                "referenceCount": 59,
                "citationCount": 7,
                "influentialCitationCount": 2,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2842549",
                        "name": "Z. Assylbekov"
                    },
                    {
                        "authorId": "153524633",
                        "name": "Jonathan North Washington"
                    },
                    {
                        "authorId": "3262036",
                        "name": "Francis M. Tyers"
                    },
                    {
                        "authorId": "3323292",
                        "name": "Assulan Nurkas"
                    },
                    {
                        "authorId": "3462536",
                        "name": "A. Sundetova"
                    },
                    {
                        "authorId": "25072615",
                        "name": "A. Karibayeva"
                    },
                    {
                        "authorId": "3459472",
                        "name": "B. Abduali"
                    },
                    {
                        "authorId": "50697743",
                        "name": "D. Amirova"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "aa4137f9682ec30b5ea729133c21115705e030ac",
                "externalIds": {
                    "MAG": "2781316112",
                    "CorpusId": 196023173
                },
                "url": "https://www.semanticscholar.org/paper/aa4137f9682ec30b5ea729133c21115705e030ac",
                "title": "Am\u00e9liorer la pr\u00e9cision d\u2019annotation d\u2019un corpus Igbo parreconstruction morphologique et l\u2019apprentissage bas\u00e9 sur latransformation",
                "abstract": "Improving Accuracy of Igbo Corpus Annotation Using Morphological Reconstruction and Transformation-Based Learning. This paper describes a method that has been used to improve the correctness of a part-of-speech (POS) tagged corpus of Igbo (an agglutinative African language), focussing on inflected words. First, morphological reconstruction (a linguistically-informed segmentation into roots and affixes) was applied to identify inflected words and segment them. Then, this information was used together with transformation-based learning (TBL, a machine learning algorithm) to flag words that were candidates for having been incorrectly tagged in the corpus, and to suggest a replacement tag, so that a human expert could accept or reject these changes. To assess the impact of this process on the corpus, we used it to train a POS tagger. During Igbo tagging, the majority of unknown words (i.e. words not seen in the training data) arise due to inflection. We found that tagging accuracy for unknown words increased from 77.77% to 83.43%, and for inflected unknown words from 58.01% to 86.81%. ABSTRACT Igbo : Nkwarite O. di. Mma Igbo Corpus Site N\u2019iji Morphological Reconstruction Na Transformation-Based Learning.Igbo : Nkwarite O. di. Mma Igbo Corpus Site N\u2019iji Morphological Reconstruction Na Transformation-Based Learning. Edemede a na-ako. wa usoro nke e ji kwarite ndi.wanye mma nke nkejiasu. su. -okwu akpadoro na corpus Igbo (asu. su. agglutinative nke Africa), tu.madi. n\u2019okwu ndi. nwere mo. fi.m. Mbu. , e ji morphological reconstruction (bu. maka ikewapu. ta mgbo. ro. gwu. -okwu na irihiri-okwu (mo. fi.m) di. n\u2019ime okwu nwere ha) wee mee ka amata okwu ndi. nwere irihiri-okwu. Mgbe nke a gasi.ri., amamihe di. n\u2019ime nkewapu. ta a na Transformation-Based Learning (TBL, igwe mmu. ta algo. ridim o. mu. mu. ) jiko. ro. aka o. nu. wee ru. ba aka ebe niile okwu ndi. nwere mo. fi.m n\u2019ime ha ma ha enweghi. ezigbo mkpado nkejiasu. su. -okwu nke n\u2019egosipu. ta na ha nwere mo. fi.m, na na-atu.kwa aro nno. chi mkpado nkejiasu. su. -okwu, nke mere na mmadu. o.kachamara nwere ike i.nabata ma o. bu. ju. mgbanwe ndi. a. I.mata mmetu. ta nke usoro a na corpus a, anyi. ejiri ya zu. a POS tagger. N\u2019oge o. zu. zu. POS tagger, o. tu. tu. okwu ndi. ana amaghi. (okwu ndi. POS tagger na-ahu.ghi. oge o. zu. zu. ) bu. maka mo. fi.m di. n\u2019ime ha. Anyi. cho.pu. tara na mkpado ziri ezi maka okwu ndi. niile ana amaghi. di.wanyere mma site na 77.77% rue 83.43% na okwu ndi. ana amaghi. nwere mo. fi.m di.wanyekwara mma site na 58.01% rue 86.81%. MOTS-CL\u00c9S : Corpus, partie du discours, l\u2019apprentissage bas\u00e9 sur la transformation, l\u2019apprentissage de la machine, Igbo, morpho Reconstruction logique, Morphologie ou affixes, mots inconnus.",
                "venue": "",
                "year": 2016,
                "referenceCount": 19,
                "citationCount": 2,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Art"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Art",
                        "source": "external"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2065335746",
                        "name": "Ikechukwu E. Onyenwe"
                    },
                    {
                        "authorId": "2065660032",
                        "name": "Mark Hepple"
                    },
                    {
                        "authorId": "2081455925",
                        "name": "C. Uchechukwu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "af7edf3b24930d0140be0d30870a73a8d7b0dddb",
                "externalIds": {
                    "MAG": "2480904509",
                    "DBLP": "conf/slate/PintoOA16",
                    "DOI": "10.4230/OASIcs.SLATE.2016.3",
                    "CorpusId": 14029125
                },
                "url": "https://www.semanticscholar.org/paper/af7edf3b24930d0140be0d30870a73a8d7b0dddb",
                "title": "Comparing the Performance of Different NLP Toolkits in Formal and Social Media Text",
                "abstract": "Nowadays, there are many toolkits available for performing common natural language processing tasks, which enable the development of more powerful applications without having to start from scratch. In fact, for English, there is no need to develop tools such as tokenizers, part-of-speech (POS) taggers, chunkers or named entity recognizers (NER). The current challenge is to select which one to use, out of the range of available tools. This choice may depend on several aspects, including the kind and source of text, where the level, formal or informal, may influence the performance of such tools. In this paper, we assess a range of natural language processing toolkits with their default configuration, while performing a set of standard tasks (e.g. tokenization, POS tagging, chunking and NER), in popular datasets that cover newspaper and social network text. \nThe obtained results are analyzed and, while we could not decide on a single toolkit, this exercise was very helpful to narrow our choice.",
                "venue": "SLATE",
                "year": 2016,
                "referenceCount": 180,
                "citationCount": 51,
                "influentialCitationCount": 2,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "46870318",
                        "name": "A. Pinto"
                    },
                    {
                        "authorId": "145275796",
                        "name": "Hugo Gon\u00e7alo Oliveira"
                    },
                    {
                        "authorId": "2068752389",
                        "name": "A. Alves"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "contexts": [
                "In relation to memory-based learning, the representative is the memorybased tagger (mbt) (Daelemans et al., 1996), while we chose svmtool (Gim\u00e9nez and M\u00e1rquez, 2004) to describe the behaviour with respect to a support vector machine technique.",
                "In relation to memory-based learning, the representative is the memorybased tagger (mbt) (Daelemans et al., 1996), while we chose svmtool (Gime\u0301nez and Ma\u0301rquez, 2004) to describe the behaviour with respect to a support vector machine technique.",
                "Thus, we then distinguish between supervised (Brants, 2000; Brill, 1995; Daelemans et al., 1996; Gim\u00e9nez and M\u00e1rquez, 2004; Schmid, 1994; Toutanova et al., 2003), semi-supervised (S\u00f8gaard, 2010; Spoustov\u00e1 et al.",
                "Thus, we then distinguish between supervised (Brants, 2000; Brill, 1995; Daelemans et al., 1996; Gime\u0301nez and Ma\u0301rquez, 2004; Schmid, 1994; Toutanova et al., 2003), semi-supervised (S\u00f8gaard, 2010; Spoustova\u0301 et al., 2009) and unsupervised (Goldwater and Griffiths, 2007; Merialdo, 1994; Ravi and\u2026"
            ],
            "citingPaper": {
                "paperId": "da9e9645e5dad9e26ae3802bec50753b1cbd7b1a",
                "externalIds": {
                    "CorpusId": 52084151
                },
                "url": "https://www.semanticscholar.org/paper/da9e9645e5dad9e26ae3802bec50753b1cbd7b1a",
                "title": "Prior estimation of post accuracy",
                "abstract": "We introduce an algorithm to estimate the evolution of accuracy in part-of-speech tagging on the whole of a training corpus, based on the results obtained from a portion of the latter. The technique approximates iteratively the vallue that we seek in the position desired, independently of the statistical model and dataset used. The process proves to be formally correct with respect to our working specifications and includes a stable stopping criterion. This allows the user to fix a reliable convergence threshold with respect to the accuracy finally achievable. Our aim is to evaluate the training effort, supporting decision making in order to reduce the need for both human and computational resources during tagger generation. The proposal is of interest in at least three operational procedures. The first is the anticipation of accuracy gain, with the purpose of measuring how much work is needed to achieve a certain level of performance. The second relates the comparison between taggers at training time, with the objective of completing this task only for the tool that predictably better suits our requirements. The prediction of accuracy is also a valuable item of information for the customization of the tagger, for example to select the tag-set, since we can estimate in advance its impact on both the performance and the development costs. The experiments corroborate our initial expectations.",
                "venue": "",
                "year": 2016,
                "referenceCount": 69,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1730828",
                        "name": "M. Ferro"
                    },
                    {
                        "authorId": "9415602",
                        "name": "V. Bilbao"
                    },
                    {
                        "authorId": "144627739",
                        "name": "F. J. Pena"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "The part-of-speech tagging was trained based on a memory-based tagger [5]."
            ],
            "citingPaper": {
                "paperId": "e0f6daea43a75ad1d1ed5b3e13829e1fd769aed5",
                "externalIds": {
                    "MAG": "2505926015",
                    "DBLP": "conf/propor/CostaC16",
                    "DOI": "10.1007/978-3-319-41552-9_32",
                    "CorpusId": 37247868
                },
                "url": "https://www.semanticscholar.org/paper/e0f6daea43a75ad1d1ed5b3e13829e1fd769aed5",
                "title": "Towards a Statistical-Enriched Corpus Containing Portuguese Collocations in Use: Reviewing Possible Extraction Tools",
                "abstract": "Collocations are a main problem for any natural language processing task, from machine translation to summarization. With the goal of building a corpus with collocations, enriched with statistical information about them, we survey, in this paper, four tools for extracting collocations. These tools allow us to collect sentences with collocations, and also to gather statistics on this particular type of co-ocurrences, like Mutual Information and Log likelihood values.",
                "venue": "PROPOR",
                "year": 2016,
                "referenceCount": 12,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "143903470",
                        "name": "\u00c2ngela Costa"
                    },
                    {
                        "authorId": "1771718",
                        "name": "Lu\u00edsa Coheur"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Manakala contoh yang mengguna teknik pembelajaran mesin seperti pembelajaran berasaskan ingatan (Daelemans et al., 1996), pepohon keputusan (M\u00e0rquez & Rodr\u00edguez, 1997), AdaBoost (Abney et al., 1999), dan Mesin Vektor Sokongan (MVS) (Nakagawa et al., 2001)."
            ],
            "citingPaper": {
                "paperId": "11a1ac720368c5221b490fb67edac4447ab751a0",
                "externalIds": {
                    "MAG": "1858557067",
                    "DOI": "10.17576/APJITM-2015-0401-02",
                    "CorpusId": 61024795
                },
                "url": "https://www.semanticscholar.org/paper/11a1ac720368c5221b490fb67edac4447ab751a0",
                "title": "Malay Part of Speech Tagger: A Comparative Study on Tagging Tools",
                "abstract": "Bahasa Melayu merupakan bahasa aglutinatif yang kaya dengan morfologi untuk menerbitkan perkataan dengan makna selain daripada kata akar yang akan memberi kesan kepada perubahan golongan katanya. Korpus beranotasi Bahasa Melayu sukar didapati, maka belum ada penerbitan tentang perbandingan prestasi penandaan golongan kata (GK) menggunakan kaedah Model Markov Tersembunyi (MMT), Entropi Maksimum (EM) dan Mesin Vektor Sokongan (MVS), terutamanya bagi melihat kesan morfologi Bahasa Melayu ke atas penandaan GK bagi perkataan anu. Kertas ini bertujuan untuk membentangkan penilaian ketiga-tiga kaedah tersebut ke atas Bahasa Melayu. Tiga alatan penanda GK telah digunakan yakni TnT mewakili MMT, MaxEnt mewakili EM dan SVMTool mewakili MVS. Bagi melengkapkan latihan dan ujian bagi ketiga-tiga alatan tersebut, usaha menganotasi korpus Bahasa Melayu bagi domain kesihatan telah dilakukan. Alatan TnT diubahsuai untuk memasukkan fitur imbuhan awalan serta apitan. Keputusan bagi seluruh eksperimen menunjukkan prestasi SVMTool mengatasi TnT dan MaxEnt bagi kejituan keseluruhan (99.23% untuk SVMTool , 94% untuk TnT dan 96% untuk MaxEnt ) serta kejituan penandaan perkataan anu (96.78% untuk SVMTool , 67% untuk TnT dan 86.23% untuk MaxEnt ). Keupayaan MaxEnt pula mengatasi TnT bagi kejituan keseluruhan serta kejituan penandaan perkataan anu. Dengan penandaan perkataan anu sebanyak 96.78% ketepatan oleh SVMTool , maka isu penandaan GK Bahasa Melayu bagi domain spesifik dianggap telah selesai.",
                "venue": "",
                "year": 2015,
                "referenceCount": 21,
                "citationCount": 5,
                "influentialCitationCount": 1,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Mathematics"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Mathematics",
                        "source": "external"
                    }
                ],
                "authors": [
                    {
                        "authorId": "146914693",
                        "name": "H. Mohamed"
                    },
                    {
                        "authorId": "143999897",
                        "name": "N. Omar"
                    },
                    {
                        "authorId": "9281843",
                        "name": "M. J. Aziz"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "29eee5866750badf401590130462ff3e1846241f",
                "externalIds": {
                    "MAG": "2235491463",
                    "DOI": "10.5753/CBIE.WCBIE.2015.95",
                    "CorpusId": 112304158
                },
                "url": "https://www.semanticscholar.org/paper/29eee5866750badf401590130462ff3e1846241f",
                "title": "AVALIA\u00c7\u00c3O AUTOM\u00c1TICA DE ATIVIDADES ESCRITAS BASEADA EM ALGORITMO GEN\u00c9TICO E PROCESSAMENTO DE LINGUAGEM NATURAL: Avaliador Ortogr\u00e1fico-Gramatical",
                "abstract": "The use of information and communication technologies - ICT is increasingly standing out in Education. With the use of automatic correction technics performed by computers, there is a bigger fluidity of activities and a relevant decrease of work for the teachers, leaving them free to create and evaluate others activities. This monograph presents a Grammatical-Orthographic Analyzer for automatic evaluation of written Activities using Genetic Algorithms and Natural Language Processing - NLP, for automate the lexicon and spelling correction of written activities.",
                "venue": "",
                "year": 2015,
                "referenceCount": 15,
                "citationCount": 2,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Engineering"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Engineering",
                        "source": "external"
                    },
                    {
                        "category": "Education",
                        "source": "s2-fos-model"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "144316714",
                        "name": "J\u00e1rio Jos\u00e9"
                    },
                    {
                        "authorId": "151190898",
                        "name": "R. Paiva"
                    },
                    {
                        "authorId": "2074074908",
                        "name": "I. Bittencourt"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "ad36f70a68d1b2d0cb47f60e5f3751115467ebb9",
                "externalIds": {
                    "MAG": "2304149179",
                    "DOI": "10.1109/KBEI.2015.7436056",
                    "CorpusId": 8830474
                },
                "url": "https://www.semanticscholar.org/paper/ad36f70a68d1b2d0cb47f60e5f3751115467ebb9",
                "title": "PTokenizer: POS tagger Tokenizer",
                "abstract": "By the advent of new information sources and the expansion of text data, natural language processing (NLP) has become one of the key parts of all the systems dealing with human written texts, and part of speech (POS) tagging is an inseparable part of all NLP tasks. As a result, it is of the paramount importance to enhance the accuracy of POS tagging. In this paper, applying language model and statistical information, we introduce a new approach to tokenize sentences and prepare them to be labeled by POS taggers. An evaluation shows that the proposed method yields a precision of 98 percent for tokenizing, and applying it to a Maximum Likelihood and TnT POS taggers achieve improvement in the accuracy of Persian POS tagging.",
                "venue": "2015 2nd International Conference on Knowledge-Based Engineering and Innovation (KBEI)",
                "year": 2015,
                "referenceCount": 9,
                "citationCount": 2,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "31140119",
                        "name": "Saeed Rahmani Seyyed"
                    },
                    {
                        "authorId": "2090727857",
                        "name": "Mostafa Fakhrahmad"
                    },
                    {
                        "authorId": "31516590",
                        "name": "M. H. Sadredini"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "contexts": [
                "Moreover, various other related methodologies (not specific to Modern Greek language) have been proposed, i.e: (1) the complement types (Bresnan, 1979), (2) the YAP parser (Church, 1980), (3) the grammatical relations (Kaplan and Bresnan, 1982), (4) the lexical disambiguation rules (Church, 1988), (5) the memory-based (POS) Tagger-Generator (Daelemans et al., 1996), (6) the flexible POS tagger using an automatically\nCorrespondence: Panagiotis Gakis, Department of Primary Education, University of Patras, University campus, 26504, Rio, Greece.",
                "1980), (3) the grammatical relations (Kaplan and Bresnan, 1982), (4) the lexical disambiguation rules (Church, 1988), (5) the memory-based (POS) Tagger-Generator (Daelemans et al., 1996), (6)",
                "MBT: A memory-based part of speech Tagger-Generator.",
                "\u2026grammatical relations (Kaplan and Bresnan, 1982), (4) the lexical disambiguation rules (Church, 1988), (5) the memory-based (POS) Tagger-Generator (Daelemans et al., 1996), (6) the flexible POS tagger using an automatically\nCorrespondence: Panagiotis Gakis, Department of Primary Education,\u2026"
            ],
            "citingPaper": {
                "paperId": "b494dd7b5e68df26c3392015d8511464ad6cec58",
                "externalIds": {
                    "DBLP": "journals/lalc/GakisPST15",
                    "MAG": "1989678401",
                    "DOI": "10.1093/llc/fqt035",
                    "CorpusId": 12677606
                },
                "url": "https://www.semanticscholar.org/paper/b494dd7b5e68df26c3392015d8511464ad6cec58",
                "title": "Analysis of lexical ambiguity in Modern Greek using a computational lexicon",
                "abstract": "Ambiguity is one of the most significant problems in Natural Language Processing. This difficulty may not be apparent to native speakers because of their natural ability at resolving it using contextual information and common sense knowledge. In contrast, current computer applications are still lacking the ability to disambiguate complex texts efficiently. The most common type of ambiguity is lexical ambiguity, and this is noticed even in highly inflectional languages such as Greek. In the present article, all the patterns of predictable lexical ambiguity in Modern Greek Language are registered, verified and quanti- fied as occurred in the Neurolingo computational lexicon, after a study of morpho-syntactic characteristics that differentiate the ambiguous words.",
                "venue": "Digit. Scholarsh. Humanit.",
                "year": 2015,
                "referenceCount": 42,
                "citationCount": 4,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2834312",
                        "name": "P. Gakis"
                    },
                    {
                        "authorId": "1749926",
                        "name": "C. Panagiotakopoulos"
                    },
                    {
                        "authorId": "1726437",
                        "name": "K. Sgarbas"
                    },
                    {
                        "authorId": "1901077",
                        "name": "C. Tsalidis"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "e30dadcc48e5f9ecc0fea07bd338c44b7df5ea4b",
                "externalIds": {
                    "MAG": "2191685195",
                    "CorpusId": 58003813
                },
                "url": "https://www.semanticscholar.org/paper/e30dadcc48e5f9ecc0fea07bd338c44b7df5ea4b",
                "title": "Desambigua\u00e7\u00e3o de anota\u00e7\u00f5es morfossint\u00e1ticas feitas por MTMDD",
                "abstract": "The Natural Language Processing technologies (PLN) are being used for analysis of huge amounts of data. With the advent of new media and mass adoption of social networking, the flow of information generated every second is the largest in history. The majority of that is multimedia files. Meanwhile, a large portion of the information produced, especially in social network, is textual. Thus, PLN solutions need to be more robust than they ever were, finding processing solutions that might accompany this constant information production or at least provide better results compared to procedures previously used. The labelers or taggers are a major component of PLN. Its function, explored in this work is the ability to observe and catalog the words in a text according to their morphosyntactic functions. The name commonly given to this process is the POST (Part-Of-Speech Tagging). Within the context Part-Of-Speech (POS) is the function to process and identify a group of words by grouping them into pre-defined types. This grouping can occur due to syntactic, morphological or morphosyntactic. Although the processing speed is a worthy feature, when we deal with labelers, the accuracy obtained for its process should be the premise. The concept of obtaining semantic labels from texts evaluations seems simple at first sight, although presents several challenges. One of the major challenges encountered in PLN is the problem of ambiguity. This situation, which occurs in several stages of natural language processing, is complex due to requires comprehensive knowledge from the processing application using that as tools to collaborate in order to implement the most correct choices. It is a classic problem, inherent to natural and existing language since the beginning of the researches of this area. Several possibilities to minimize its consequences have been proposed since then. This paper lists some of the proposals found on the literature by adding the possibility to use MTMDD structures during the process, looking for a substantial performance gain.",
                "venue": "",
                "year": 2015,
                "referenceCount": 28,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "67112439",
                        "name": "P. Frederico"
                    },
                    {
                        "authorId": "50755825",
                        "name": "Oliveira Thiele"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "23987cdcc39e8134d12591b024ba9415e8b290f8",
                "externalIds": {
                    "MAG": "2127323505",
                    "DOI": "10.1051/SHSCONF/20140801035",
                    "CorpusId": 190689086
                },
                "url": "https://www.semanticscholar.org/paper/23987cdcc39e8134d12591b024ba9415e8b290f8",
                "title": "TALC-sef, Un corpus \u00e9tiquet\u00e9 de traductions litt\u00e9raires en serbe, anglais et fran\u00e7ais",
                "abstract": "Le corpus TALC-sef (TAgged Literary Corpus in Serbian, English, French) est un corpus parallele d'ouvrages litteraires en serbe, anglais et francais, etiquetes en parties du discours et librement consultables via une interface en ligne. Il a ete constitue par l'Universite d'Arras, en collaboration avec l'Universite Lille 3 et l'Universite de Belgrade, dans une perspective d'etudes comparees en stylistique et linguistique. Le corpus TALC-sef represente au total plus de 2 millions de mots, il integre notamment un corpus etiquete, corrige manuellement pour la langue serbe, de 150 000 mots. Dans cet article, nous presentons le mode de constitution du corpus parallele dans son ensemble, puis nous nous attachons plus specifiquement a l'elaboration du sous-corpus serbe etiquete. Nous detaillons les choix linguistiques et techniques sous-jacents a la constitution de ce sous-corpus, qui vient completer l'offre existante pour la linguistique sur corpus en serbe: a ce jour, le seul corpus librement disponible consiste en une traduction du roman 1984 de G. Orwell (100 000 mots), alors que nous proposons un corpus d'\u0153uvres ecrites a l'origine en Serbe, de 150 000 mots. La constitution de ce sous-corpus a permis l'elaboration de modeles d'etiquetage automatique pour trois etiqueteurs syntaxiques, dont Treetagger, TnT et BTagger, le plus efficace d'entre eux. Enfin, nous presentons les perspectives d'evolution du corpus existant, en termes d'enrichissement des annotations syntaxiques (analyses en dependance en parallele sur les trois langues), ainsi que les apports d'un tel corpus parallele etiquete pour la linguistique du francais.",
                "venue": "",
                "year": 2014,
                "referenceCount": 28,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Art"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Art",
                        "source": "external"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2640846",
                        "name": "A. Balvet"
                    },
                    {
                        "authorId": "2078083",
                        "name": "D. Stosic"
                    },
                    {
                        "authorId": "2079137372",
                        "name": "Aleksandra Miletic"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "2633280c237fd5c738a63acbb4ee37fbd34443e0",
                "externalIds": {
                    "MAG": "2251615317",
                    "DBLP": "conf/lrec/BalvetSM14",
                    "ACL": "L14-1591",
                    "CorpusId": 13855599
                },
                "url": "https://www.semanticscholar.org/paper/2633280c237fd5c738a63acbb4ee37fbd34443e0",
                "title": "TALC-sef A Manually-Revised POS-TAgged Literary Corpus in Serbian, English and French",
                "abstract": "In this paper, we present a parallel literary corpus for Serbian, English and French, the TALC-sef corpus. The corpus includes a manually-revised pos-tagged reference Serbian corpus of over 150,000 words. The initial objective was to devise a reference parallel corpus in the three languages, both for literary and linguistic studies. The French and English sub-corpora had been pos-tagged from the onset, using TreeTagger (Schmid, 1994), but the corpus lacked, until now, a tagged version of the Serbian sub-corpus. Here, we present the original parallel literary corpus, then we address issues related to pos-tagging a large collection of Serbian text: from the conception of an appropriate tagset for Serbian, to the choice of an automatic pos-tagger adapted to the task, and then to some quantitative and qualitative results. We then move on to a discussion of perspectives in the near future for further annotations of the whole parallel corpus.",
                "venue": "LREC",
                "year": 2014,
                "referenceCount": 29,
                "citationCount": 5,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2078274663",
                        "name": "Antonio Balvet"
                    },
                    {
                        "authorId": "2076356941",
                        "name": "D. Stosic"
                    },
                    {
                        "authorId": "1610551247",
                        "name": "A. Miletic"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Daelemans et al. (1999)[13] use memory based system and evaluates the system and reports a good performance."
            ],
            "citingPaper": {
                "paperId": "426d9553b99f7b3bbe2e86c4be4d2d83e559df80",
                "externalIds": {
                    "MAG": "1998329272",
                    "DOI": "10.1109/ICBIM.2014.6970957",
                    "CorpusId": 16458130
                },
                "url": "https://www.semanticscholar.org/paper/426d9553b99f7b3bbe2e86c4be4d2d83e559df80",
                "title": "Bengali noun phrase chunking based on conditional random fields",
                "abstract": "Noun phrase (NP) chunking deals with extracting the noun phrases from a sentence. While NP chunking is much simpler than parsing, it is still a challenging task to build an accurate and efficient NP chunker. Noun phrase chunking is an important and useful task in many natural language processing applications. It is studied well for English, however not much work has been done for Bengali. This paper presents a Bengali noun phrase chunking approach based on conditional random fields (CRFs) models. Our developed NP chunker has been tested on the ICON 2013 dataset and achieves an impressive F-score of 95.92.",
                "venue": "2014 2nd International Conference on Business and Information Management (ICBIM)",
                "year": 2014,
                "referenceCount": 23,
                "citationCount": 3,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "34062168",
                        "name": "K. Sarkar"
                    },
                    {
                        "authorId": "2447711",
                        "name": "V. Gayen"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "We use the Memory Based Tagger (Daelemans et al., 1996) trained on the Brown corpus to compute the part-of-speech tags."
            ],
            "citingPaper": {
                "paperId": "67fae208d0e8ef14ce3b7835d73322d50c2d8cea",
                "externalIds": {
                    "ACL": "L14-1094",
                    "DBLP": "conf/lrec/WubbenBK14",
                    "MAG": "2123678043",
                    "CorpusId": 219309700
                },
                "url": "https://www.semanticscholar.org/paper/67fae208d0e8ef14ce3b7835d73322d50c2d8cea",
                "title": "Creating and using large monolingual parallel corpora for sentential paraphrase generation",
                "abstract": "In this paper we investigate the automatic generation of paraphrases by using machine translation techniques. Three contributions we make are the construction of a large paraphrase corpus for English and Dutch, a re-ranking heuristic to use machine translation for paraphrase generation and a proper evaluation methodology. A large parallel corpus is constructed by aligning clustered headlines that are scraped from a news aggregator site. To generate sentential paraphrases we use a standard phrase-based machine translation (PBMT) framework modified with a re-ranking component (henceforth PBMT-R). We demonstrate this approach for Dutch and English and evaluate by using human judgements collected from 76 participants. The judgments are compared to two automatic machine translation evaluation metrics. We observe that as the paraphrases deviate more from the source sentence, the performance of the PBMT-R system degrades less than that of the word substitution baseline system.",
                "venue": "LREC",
                "year": 2014,
                "referenceCount": 46,
                "citationCount": 5,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1917518",
                        "name": "S. Wubben"
                    },
                    {
                        "authorId": "145977875",
                        "name": "Antal van den Bosch"
                    },
                    {
                        "authorId": "145210073",
                        "name": "E. Krahmer"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "For example, the probability of having a verb is more likely than using an article after a modal [2]."
            ],
            "citingPaper": {
                "paperId": "69b032ea3768a8457a376e75930761f102c6ffe5",
                "externalIds": {
                    "CorpusId": 173983878
                },
                "url": "https://www.semanticscholar.org/paper/69b032ea3768a8457a376e75930761f102c6ffe5",
                "title": "Modeling a modern POS tagger using HMM and Viterbi Algorithm",
                "abstract": "The paper presents a modern way of an improved POS tagger which was modeled by using Hidden Markov Model and Viterbi Algorithm. The algorithm provides ideas for handling unknown words. This issue is caused by such words that have the same spelling but relate to complete different parts of speech and have various meanings. The accuracy of such POS tagger exceeds 96%. Such algorithm\u2019s accuracy was analyzed to other existing algorithms and suggestions were provided.",
                "venue": "",
                "year": 2014,
                "referenceCount": 12,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "143748562",
                        "name": "A. Vorobiev"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "7e72de084641a3ed512dec60e56186b321c33d28",
                "externalIds": {
                    "MAG": "2070037549",
                    "DOI": "10.1016/J.APM.2013.11.047",
                    "CorpusId": 62180925
                },
                "url": "https://www.semanticscholar.org/paper/7e72de084641a3ed512dec60e56186b321c33d28",
                "title": "Hybrid PoS-tagging: A cooperation of evolutionary and statistical approaches",
                "abstract": null,
                "venue": "",
                "year": 2014,
                "referenceCount": 44,
                "citationCount": 7,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1683333",
                        "name": "R. Forsati"
                    },
                    {
                        "authorId": "2567327",
                        "name": "M. Shamsfard"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "However, the rules can be learned (Hindle, 1989, Daelemans et al., 1995) or the transformation-based error-driven approach of Brill (1992b).",
                "These rules can be provided manually (Klein and Simmons, 1963, Daelemans et al., 1995).",
                "51\n51\nMost works based on statistical methods have used n-gram models or Hidden\nMarkov Model-based taggers (Church, 1988, DeRose, 1988, Cutting et al., 1992, Daelemans et al., 1995)."
            ],
            "citingPaper": {
                "paperId": "a98867dec6c723a4a45e8da76859e24d6c61959c",
                "externalIds": {
                    "MAG": "62267907",
                    "CorpusId": 59821066
                },
                "url": "https://www.semanticscholar.org/paper/a98867dec6c723a4a45e8da76859e24d6c61959c",
                "title": "Ontology-based knowledge discovery from unstructured and semi-structured text",
                "abstract": "............................................................................................................................ i ACKNOWLEDGEMENTS ................................................................................................... iii TABLE OF CONTENTS ....................................................................................................... iv LIST OF FIGURES .............................................................................................................. vii LIST OF TABLES .................................................................................................................. x 1.1 Background .............................................................................................................. 13 1.2 Motivations .............................................................................................................. 14 1.3 Research Questions .................................................................................................. 14 1.4 Research Contributions ............................................................................................ 15 1.5 Thesis Content .......................................................................................................... 17 2.1 Literature Reviews ................................................................................................... 19 2.1.1 Knowledge Acquisition ..................................................................................... 19 2.1.2 Data Mining and Knowledge Discovery in Database ....................................... 21 2.1.3 The KDD Process Model................................................................................... 21 2.1.4 Comparison of the KDD Process Models ......................................................... 24 2.1.5 Problems of Applying the KDD process for Informal Data .............................. 27 2.2 Improvement of Knowledge Discovery Methodology ............................................. 29 2.3 Related Concepts and Techniques ........................................................................... 31 2.3.1 Ontology Development ..................................................................................... 31 2.3.2 Natural Language Processing ............................................................................ 39 2.3.3 N-gram............................................................................................................... 46 2.3.4 Text Mining ....................................................................................................... 48 2.3.5 Closed-domain question answering ................................................................... 54 2.3.6 Evaluation Measures ......................................................................................... 57 3.1 The Main Concept for the On-KDT Modelling ....................................................... 60 3.2 The Variant Lexicon Ontology Development .......................................................... 62 3.2.1 Background ....................................................................................................... 63 3.2.2 Definition of the VL-ontology........................................................................... 65 3.2.3 The use of the VL-ontology .............................................................................. 67 3.2.4 How to implement the VL-ontology ................................................................. 68 3.2.5 Example of the use of the VL-ontology ............................................................ 72 3.2.6 The Experiments of the VL-ontology ................................................................ 73 3.3 The Elaboration of the ON-KDT methodology ....................................................... 75 3.3.1 Understanding of the application domain and defining the problem ................ 75",
                "venue": "",
                "year": 2014,
                "referenceCount": 225,
                "citationCount": 4,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2882116",
                        "name": "J. Polpinij"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "A major ambiguity is resolved by using a technique known as \u201cPart Of Speech Tagging\u201d which is defined as determining and annotating the role of all words in the sentence [1]."
            ],
            "citingPaper": {
                "paperId": "dd09b75b3ca294e1cfac686bf5322c7068a041d2",
                "externalIds": {
                    "CorpusId": 54750339
                },
                "url": "https://www.semanticscholar.org/paper/dd09b75b3ca294e1cfac686bf5322c7068a041d2",
                "title": "Word Sense Disambiguation Based on Lexical and Semantic Features UsingNaive Bayes Classifier",
                "abstract": "Machine translation is considered as a branch of machine intelligence with about fifty years background. Ambiguity of language is the most problematic issue in machine translation systems, which may lead to unclear or wrong translation. One of the problems involved in natural language processing is the semantic and structural ambiguity of the words. The objective of this paper to focused on the word sense disambiguation. In here, the existing algorithms for word sense disambiguation are evaluated and a method which is proposed based on the concept, structure and meaning of the words. The experimental results are promising and indicate that this proposed approach significantly outperform its counterparts in terms of disambiguation accuracy. c \u00a9 2014 JComSec. All rights reserved.",
                "venue": "",
                "year": 2014,
                "referenceCount": 35,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "40567388",
                        "name": "A. Rasekh"
                    },
                    {
                        "authorId": "3287969",
                        "name": "M. Sadreddini"
                    },
                    {
                        "authorId": "1946121",
                        "name": "S. M. Fakhrahmad"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "ebc2477df2b802ccc9fe3c5979aa3e2a82e7c450",
                "externalIds": {
                    "DBLP": "conf/nldb/SmedtMMD14",
                    "MAG": "164562765",
                    "DOI": "10.1007/978-3-319-07983-7_1",
                    "CorpusId": 4238473
                },
                "url": "https://www.semanticscholar.org/paper/ebc2477df2b802ccc9fe3c5979aa3e2a82e7c450",
                "title": "Using Wiktionary to Build an Italian Part-of-Speech Tagger",
                "abstract": "While there has been a lot of progress in Natural Language Processing (NLP), many basic resources are still missing for many languages, including Italian, especially resources that are free for both research and commercial use. One of these basic resources is a Part-of-Speech tagger, a first processing step in many NLP applications. We describe a weakly-supervised, fast, free and reasonably accurate part-of-speech tagger for the Italian language, created by mining words and their part-of-speech tags from Wiktionary. We have integrated the tagger in Pattern, a freely available Python toolkit. We believe that our approach is general enough to be applied to other languages as well.",
                "venue": "NLDB",
                "year": 2014,
                "referenceCount": 23,
                "citationCount": 5,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "8231390",
                        "name": "T. D. Smedt"
                    },
                    {
                        "authorId": "1911874",
                        "name": "Fabio Marfia"
                    },
                    {
                        "authorId": "145927530",
                        "name": "M. Matteucci"
                    },
                    {
                        "authorId": "1735272",
                        "name": "Walter Daelemans"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "088a8fc1920f613a3e33fae395741aae71b20181",
                "externalIds": {
                    "MAG": "2964082670",
                    "DBLP": "journals/corr/AliJ13",
                    "ArXiv": "1307.3489",
                    "DOI": "10.5121/IJNLC.2013.2301",
                    "CorpusId": 16036811
                },
                "url": "https://www.semanticscholar.org/paper/088a8fc1920f613a3e33fae395741aae71b20181",
                "title": "Genetic approach for arabic part of speech tagging",
                "abstract": "With the growing number of textual resources available, the ability to understand them becomes critical. An essential first step in understanding these sources is the ability to identify the part of speech in each sentence. Arabic is a morphologically rich language, wich presents a challenge for part of speech tagging. In this paper, our goal is to propose, improve and implement a part of speech tagger based on a genetic alorithm. The accuracy obtained with this method is comparable to that of other probabilistic approaches.",
                "venue": "ArXiv",
                "year": 2013,
                "referenceCount": 27,
                "citationCount": 12,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2843251",
                        "name": "Bilel Ben Ali"
                    },
                    {
                        "authorId": "2232868",
                        "name": "Fethi Jarray"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "This property loads many meanings to a single word."
            ],
            "citingPaper": {
                "paperId": "1a126a3ad7c6c77d7f41360a506476dabd776d77",
                "externalIds": {
                    "DBLP": "conf/ijcnlp/KutluC13",
                    "ACL": "I13-1175",
                    "MAG": "2252093148",
                    "CorpusId": 12219473
                },
                "url": "https://www.semanticscholar.org/paper/1a126a3ad7c6c77d7f41360a506476dabd776d77",
                "title": "A Hybrid Morphological Disambiguation System for Turkish",
                "abstract": "In this paper, we propose a morphological disambiguation method for Turkish, which is an agglutinative language. We use a hybrid method, which combines statistical information with handcrafted rules and learned rules. Five different steps are applied for disambiguation. In the first step, the most likely tags of words are selected. In the second step, we use handcrafted rules to constrain possible parses or select the correct parse. Next, the most likely tags are selected for still ambiguous words according to the suffixes of the words that are unseen in the training corpus. Then, we use transformation-based rules that are learned by a variation of Brill tagger. If the word is still ambiguous, we use some heuristics for the disambiguation. We constructed a hand-tagged dataset for training and applied a ten-fold cross validation with this dataset. We obtained 93.4% accuracy on the average when whole morphological parses are considered in calculation. The accuracy increased to 94.1% when only part-of-speech tags and inflections of last derivations are considered. Our accuracy is 96.9% in terms of part-of-speech tagging.",
                "venue": "IJCNLP",
                "year": 2013,
                "referenceCount": 17,
                "citationCount": 8,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "33407644",
                        "name": "Mucahid Kutlu"
                    },
                    {
                        "authorId": "3188981",
                        "name": "I. \u00c7i\u00e7ekli"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "25396aa4d4e5f008b94b554fc363a31384e07dc9",
                "externalIds": {
                    "DBLP": "journals/kais/ForsatiS15",
                    "MAG": "1975664638",
                    "DOI": "10.1007/s10115-013-0719-6",
                    "CorpusId": 10888881
                },
                "url": "https://www.semanticscholar.org/paper/25396aa4d4e5f008b94b554fc363a31384e07dc9",
                "title": "Novel harmony search-based algorithms for part-of-speech tagging",
                "abstract": "As a fast and high-quality tagger algorithm is a crucial task in natural language processing, this paper presents novel language-independent algorithms based on harmony search (HS) optimization method for handling the part-of-speech (PoS) tagging problem. The first proposed algorithm is a framework for applying HS to PoS-tagging which is called HSTAGger. By modifying HS algorithm and proposing more efficient objective functions, two improved versions of the HSTAGger are also introduced. In addition, a novel class of problematic words called erroneous as well as a method of handling them is proposed for the first time to the best of our knowledge. To demonstrate the effectiveness of the proposed algorithms, we have applied them on standard annotated corpus and compare them with other evolutionary-based and classical PoS-tagging approaches. Experimental results indicate that the proposed algorithms outperform the other taggers previously presented in the literature in terms of average precision.",
                "venue": "Knowledge and Information Systems",
                "year": 2015,
                "referenceCount": 57,
                "citationCount": 10,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1683333",
                        "name": "R. Forsati"
                    },
                    {
                        "authorId": "2567327",
                        "name": "M. Shamsfard"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "\u2026statistical approaches in his framework of transformation-based learning and Ratnaparkhi (1996) pioneered the use of maximum entropy models (Berger et al., 1996), while Daelemans et al. (1996) popularized the use of memory-based learning (Daelemans and van den Bosch, 2005) for this and other tasks."
            ],
            "citingPaper": {
                "paperId": "2b2f1fc2b68f7d60225d27ff4a64216d9794828e",
                "externalIds": {
                    "DBLP": "phd/basesearch/Tackstrom13",
                    "MAG": "197170904",
                    "CorpusId": 27588178
                },
                "url": "https://www.semanticscholar.org/paper/2b2f1fc2b68f7d60225d27ff4a64216d9794828e",
                "title": "Predicting Linguistic Structure with Incomplete and Cross-Lingual Supervision",
                "abstract": "Contemporary approaches to natural language processing are predominantly based on statistical machine learning from large amounts of text, which has been manually annotated with the linguistic stru ...",
                "venue": "",
                "year": 2013,
                "referenceCount": 532,
                "citationCount": 17,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2556289",
                        "name": "Oscar T\u00e4ckstr\u00f6m"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "33f0e850455b17cae0e7fc56c9aaf043faf918db",
                "externalIds": {
                    "MAG": "2250199935",
                    "CorpusId": 61754173
                },
                "url": "https://www.semanticscholar.org/paper/33f0e850455b17cae0e7fc56c9aaf043faf918db",
                "title": "Establishing the reliability of natural language processing evaluation through linear regression modelling",
                "abstract": "Thesis (PhD (Linguistics and Literary Theory))--North-West University, Potchefstroom Campus, 2013.",
                "venue": "",
                "year": 2013,
                "referenceCount": 114,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Education",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "72746325",
                        "name": "Ernst Roald Eiselen"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "For each of the two classification tasks (i.e., segmentation and POS tagging), we use MBT (Daelemans et al., 1996), a memory-based POS tagger that has access to previous tagging decisions in addition to an expressive feature set.",
                "Procedure: We performed a non-exhaustive search for optimal settings for the following MBT parameters: the MBL algorithm, the similarity metric, the feature weighting method, and the value of the k nearest neighbors.",
                ", segmentation and POS tagging), we use MBT (Daelemans et al., 1996), a memory-based POS tagger that has access to previous tagging decisions in addition to an expressive feature set."
            ],
            "citingPaper": {
                "paperId": "626f3c1b5b2669bbbe4439c6692472f7369d888b",
                "externalIds": {
                    "MAG": "2251354811",
                    "ACL": "R13-1001",
                    "DBLP": "conf/ranlp/Abdul-MageedDK13",
                    "CorpusId": 1720647
                },
                "url": "https://www.semanticscholar.org/paper/626f3c1b5b2669bbbe4439c6692472f7369d888b",
                "title": "ASMA: A System for Automatic Segmentation and Morpho-Syntactic Disambiguation of Modern Standard Arabic",
                "abstract": "In this paper, we present ASMA, a fast and efficient system for automatic segmentation and fine grained part of speech (POS) tagging of Modern Standard Arabic (MSA). ASMA performs segmentation both of agglutinative and of inflectional morphological boundaries within a word. In this work, we compare ASMA to two state of the art suites of MSA tools: AMIRA 2.1 (Diab et al., 2007; Diab, 2009) and MADA+TOKAN 3.2. (Habash et al., 2009). ASMA achieves comparable results to these two systems\u2019 state-of-theart performance. ASMA yields an accuracy of 98.34% for segmentation, and an accuracy of 96.26% for POS tagging with ar ich tagset and 97.59% accuracy with an extremely reduced tagset. 1I ntroduction",
                "venue": "RANLP",
                "year": 2013,
                "referenceCount": 25,
                "citationCount": 11,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1388437494",
                        "name": "Muhammad Abdul-Mageed"
                    },
                    {
                        "authorId": "1700007",
                        "name": "Mona T. Diab"
                    },
                    {
                        "authorId": "1804668",
                        "name": "Sandra K\u00fcbler"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "63e2c40e34781f5eca367d4d2f83847015c8ee7b",
                "externalIds": {
                    "MAG": "2396882518",
                    "CorpusId": 15028220
                },
                "url": "https://www.semanticscholar.org/paper/63e2c40e34781f5eca367d4d2f83847015c8ee7b",
                "title": "Arabic Morphosyntactic Raw Text Part of Speech Tagging System",
                "abstract": "We present a comprehensive Arabic tagging system: from the raw text to tagging disambiguation. For each processing step in the tagging system, we analyze the existing solutions (if any) and use one of them or propose, implement and evaluate a new one. This work began with designing a new Arabic tagset suitable for Classical Arabic (CA) and Modern Standard Arabic (MSA). In addition to the classical constructions in tag systems, we introduce interleaving of tags. Interleaving is a relation between tags which, in certain situations, can be attached to the same occurrence of a word, but each of them can also appear alone. Our tagset makes this relation explicit. Then we deal with the preparatory stages for tagging system. The first initial stage is tokenization and segmentation. We use rule-based and statistical methods for this task. The second stage is analyzing and extracting the lemma from the word. We have created our own analyzer compatible with our requirements. Its main part is a dictionary which provides features, POS and lemma for each word. The last part of our work is the tagging algorithm which produces one tag for each word. We use a hybrid method by combining rules-based and statistical methods. Three taggers, Hidden Markov Model (HMM), maximum match and Brill are combined by a new method, which we call master and slaves. Then handwritten rule-based tagger is also added to master-slaves. The rule based tagger eliminates incorrect tags, and the master chooses the best one among the remaining ones, assisted by the other slaves. Our complete system is ready to be used for annotation of Arabic corpora.",
                "venue": "",
                "year": 2013,
                "referenceCount": 100,
                "citationCount": 17,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "143719290",
                        "name": "Ahmed H. Aliwy"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "contexts": [
                "Instead of the word itself it takes into account character-based features of the word, such as the last three letters and whether it is capitalized or not [2].",
                "Memory-based tagging [2] is a generic machine-learning-based solution to structured sequence processing that is applicable to IOB-coded chunking."
            ],
            "citingPaper": {
                "paperId": "6a9ce4fd398d5ed6d48d683544745df8e7961280",
                "externalIds": {
                    "DBLP": "conf/msm/BoschB13",
                    "MAG": "1933230264",
                    "CorpusId": 16659425
                },
                "url": "https://www.semanticscholar.org/paper/6a9ce4fd398d5ed6d48d683544745df8e7961280",
                "title": "Memory-based Named Entity Recognition in Tweets",
                "abstract": "We present a memory-based named entity recognition sys- tem that participated in the MSM-2013 Concept Extraction Challenge. The system expands the training set of annotated tweets with part-of- speech tags and seedlist information, and then generates a sequential memory-based tagger comprised of separate modules for known and un- known words. Two taggers are trained: one on the original capitalized data, and one on a lowercased version of the training data. The intersec- tion of named entities in the predictions of the two taggers is kept as the final output.",
                "venue": "#MSM",
                "year": 2013,
                "referenceCount": 10,
                "citationCount": 5,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "145977875",
                        "name": "Antal van den Bosch"
                    },
                    {
                        "authorId": "1742436",
                        "name": "Toine Bogers"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "The selection of features for Named Entity Recognition was based on the research conducted by Desmet and Hoste (2010a). The same orthographic features extracted for Part-of-Speech Tagging (see Section 2."
            ],
            "citingPaper": {
                "paperId": "792b9cd220a3f5b33a2963295b53fbae46f8236b",
                "externalIds": {
                    "MAG": "2182880781",
                    "CorpusId": 61302026
                },
                "url": "https://www.semanticscholar.org/paper/792b9cd220a3f5b33a2963295b53fbae46f8236b",
                "title": "LeTs Preprocess: The multilingual LT3 linguistic preprocessing toolkit",
                "abstract": "This paper presents the LeTs Preprocess Toolkit, a suite of robust high-performance preprocessing modules including Part-of-Speech Taggers, Lemmatizers and Named Entity Recognizers. The currently supported languages are Dutch, English, French and German. We give a detailed description of the architecture of the LeTs Preprocess pipeline and describe the data and methods used to train each component. Ten-fold cross-validation results are also presented. To assess the performance of each module on dierent domains, we collected real-world textual data from companies covering various domains (a.o. automotive, dredging and human resources) for all four supported languages. For this multi-domain corpus, a manually veried gold standard was created for each of the three preprocessing steps. We present the performance of our preprocessing components on this corpus and compare it to the performance of other existing tools.",
                "venue": "CLIN 2013",
                "year": 2013,
                "referenceCount": 30,
                "citationCount": 54,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "3230414",
                        "name": "M. Kauter"
                    },
                    {
                        "authorId": "2162008",
                        "name": "Geert Coorman"
                    },
                    {
                        "authorId": "2846808",
                        "name": "Els Lefever"
                    },
                    {
                        "authorId": "2077987",
                        "name": "Bart Desmet"
                    },
                    {
                        "authorId": "3139898",
                        "name": "Lieve Macken"
                    },
                    {
                        "authorId": "2653729",
                        "name": "Veronique Hoste"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "We applied a part-of-speech tagger and text chunker for Dutch that used the memory-based tagger MBT [5], trained on the Spoken Dutch Corpus.5 Finally, grammatical relation finding was performed, using a shallow parser to determine the grammatical relation between noun chunks and verbal chunks, e.g. subject, object, etc.",
                "We applied a part-of-speech tagger and text chunker for Dutch that used the memory-based tagger MBT [5], trained on the Spoken Dutch Corpus."
            ],
            "citingPaper": {
                "paperId": "c25dbd100a8aad43d4b41a05f91c56bb6727a6a6",
                "externalIds": {
                    "DBLP": "series/tanlp/HendrickxBDH13",
                    "MAG": "2139373276",
                    "DOI": "10.1007/978-3-642-30910-6_7",
                    "CorpusId": 19006072
                },
                "url": "https://www.semanticscholar.org/paper/c25dbd100a8aad43d4b41a05f91c56bb6727a6a6",
                "title": "COREA: Coreference Resolution for Extracting Answers for Dutch",
                "abstract": "Many natural language processing applications can benefit from the identification of coreference relations. For example, in information extraction and question answering, recall should in principle increase when the available information is expanded by linking expressions in a text that refer to the same discourse entity. Most current state-of-the-art systems for coreference resolution are based on supervised machine learning, and require (large) amounts of annotated data for training and testing. As these data were lacking for Dutch, the corea project had as its goal the construction of a coreference corpus for Dutch, and the development of an automatic coreference resolution system that used the corpus as training material. In this paper, we present the results of our annotation efforts, and the design of the automatic resolution system. Furthermore, we discuss various experiments that were carried out to determine the accuracy of the resolution system and the potential benefit of incorporating coreference resolution in nlp tasks",
                "venue": "Essential Speech and Language Technology for Dutch",
                "year": 2013,
                "referenceCount": 48,
                "citationCount": 2,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1708288",
                        "name": "Iris Hendrickx"
                    },
                    {
                        "authorId": "144254013",
                        "name": "G. Bouma"
                    },
                    {
                        "authorId": "1735272",
                        "name": "Walter Daelemans"
                    },
                    {
                        "authorId": "2653729",
                        "name": "Veronique Hoste"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "c6aba0e75216fe8cf7cd0a1c13bff215f92d0369",
                "externalIds": {
                    "MAG": "2732943978",
                    "CorpusId": 196097877
                },
                "url": "https://www.semanticscholar.org/paper/c6aba0e75216fe8cf7cd0a1c13bff215f92d0369",
                "title": "Distributed Natural Language Search Using Graph-Based Parsing",
                "abstract": "Wir prasentieren die konzeptuellen und technologischen Grundlagen einer verteilten naturlich sprachlichen Suchmaschine, die einen graph-basierten Ansatz zum Parsen einer Anfrage verwendet. Das Parsing-Modell, das in dieser Arbeit entwickelt wird, generiert eine semantische Reprasentation einer naturlich sprachlichen Anfrage in einem 3-stufigen, ubergangsbasierten Verfahren, das auf probabilistischen Patterns basiert. Die semantische Reprasentation einer naturlich sprachlichen Anfrage wird in Form eines Graphen dargestellt, der Entitaten als Knoten und deren Relationen als Kanten reprasentiert. Die prasentierte Systemarchitektur stellt das Konzept einer naturlich sprachlichen Suchmaschine vor, die sowohl in Bezug auf die einbezogenen Vokabulare, die zum Parsen der Syntax und der Semantik einer eingegebenen Anfrage verwendet werden, als auch in Bezug auf die Wissensquellen, die zur Gewinnung von Suchergebnissen konsultiert werden, unabhangig ist. Diese Funktionalitat wird durch die Modularisierung der Systemkomponenten erreicht, die externe Daten durch flexible Module anspricht, welche zur Laufzeit modifiziert werden konnen. Wir evaluieren die Leistung des Systems indem wir die Genauigkeit des syntaktischen Parsers, die Prazision der gewonnenen Suchergebnisse sowie die Geschwindigkeit des Prototyps testen.",
                "venue": "",
                "year": 2013,
                "referenceCount": 54,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Mathematics"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Mathematics",
                        "source": "external"
                    }
                ],
                "authors": [
                    {
                        "authorId": "150246758",
                        "name": "Nadine Sina Kurz"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "contexts": [
                "Instead of the word itself it takes into account character-based features of the word, such as the last three letters and whether it is capitalized or not [2].",
                "Memory-based tagging [2] is a generic machine-learning-based solution to structured sequence processing that is applicable to IOB-coded chunking."
            ],
            "citingPaper": {
                "paperId": "e185af4b827bbfebbedbf69b03075a0f6cdaac76",
                "externalIds": {
                    "CorpusId": 106403111
                },
                "url": "https://www.semanticscholar.org/paper/e185af4b827bbfebbedbf69b03075a0f6cdaac76",
                "title": "Aalborg Universitet Memory-based Named Entity Recognition in Tweets",
                "abstract": "We present a memory-based named entity recognition system that participated in the MSM-2013 Concept Extraction Challenge. The system expands the training set of annotated tweets with part-ofspeech tags and seedlist information, and then generates a sequential memory-based tagger comprised of separate modules for known and unknown words. Two taggers are trained: one on the original capitalized data, and one on a lowercased version of the training data. The intersection of named entities in the predictions of the two taggers is kept as the final output.",
                "venue": "",
                "year": 2013,
                "referenceCount": 9,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "119788703",
                        "name": "Van den Bosch"
                    },
                    {
                        "authorId": "11483088",
                        "name": "A. Cano"
                    },
                    {
                        "authorId": "1409513931",
                        "name": "M."
                    },
                    {
                        "authorId": "2061154334",
                        "name": "Rowe"
                    },
                    {
                        "authorId": "2066542417",
                        "name": "M. Stankovic"
                    },
                    {
                        "authorId": "2744660",
                        "name": "Aba-Sah Dadzie"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background",
                "result"
            ],
            "contexts": [
                "The default settings, which were found to be best by Daelemans et al. (1996), are to use two tags to the left and one (ambiguous) tag to the right as context for known words, and one tag to both sides plus the first and the final three letters of unknown words.",
                "MBT claims to have an especially good performance on unknowns: on a Wall Street Journal corpus, an accuracy above 90% for unknown words was achieved (Daelemans et al., 1996).",
                "This is a remarkable difference, especially considering the high performance on unknowns reported for MBT with English corpora (Daelemans et al., 1996). It is conceivable that the results can be improved by tuning the various parameters of both the tagger and the memory-based learning framework utilized by it. Experiments with parametrization were not tried for this thesis, however, a study by Ivanova and K\u00fcbler (2008) found that tagging results on German using MBT were best when setting the context information to two tokens on both sides of the input word. The default setting used here differs from this optimum by using only one token to the right, which the study found to have only a marginal effect on the result, though. Another possible factor is the prefix length taken into account for unknown words, which is one by default, but three in the study by Ivanova and K\u00fcbler (2008). The differences in accuracy reported there by changing the tagger\u2019s settings are all comparatively minor, though, letting it appear questionable whether these settings can actually close the gap of about 6 percentage points to the other taggers.",
                "This is a remarkable difference, especially considering the high performance on unknowns reported for MBT with English corpora (Daelemans et al., 1996). It is conceivable that the results can be improved by tuning the various parameters of both the tagger and the memory-based learning framework utilized by it. Experiments with parametrization were not tried for this thesis, however, a study by Ivanova and K\u00fcbler (2008) found that tagging results on German using MBT were best when setting the context information to two tokens on both sides of the input word.",
                "This is a remarkable difference, especially considering the high performance on unknowns reported for MBT with English corpora (Daelemans et al., 1996)."
            ],
            "citingPaper": {
                "paperId": "ed2cc779c7eb0004bd6dd50538a2cafca092c94f",
                "externalIds": {
                    "CorpusId": 53621963
                },
                "url": "https://www.semanticscholar.org/paper/ed2cc779c7eb0004bd6dd50538a2cafca092c94f",
                "title": "Automatic Normalization for Linguistic Annotation of Historical Language Data",
                "abstract": "This paper deals with spelling normalization of historical texts with regard to further processing with modern part-of-speech taggers. Different methods for this task are presented and evaluated on a set of historical German texts from the 15th\u201318th century, and specific problems inherent to the processing of historical data are discussed. A chain combination using word-based and character-based techniques is shown to be best for normalization, while POS tagging of normalized data is shown to benefit from ignoring punctuation marks. Using these techniques, when 500 manually normalized tokens are used as training data for the normalization, the tagging accuracy of a manuscript from the 15th century can be raised from 28.65% to 76.27%.",
                "venue": "",
                "year": 2013,
                "referenceCount": 40,
                "citationCount": 4,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "34887843",
                        "name": "Marcel Bollmann"
                    },
                    {
                        "authorId": "2080335885",
                        "name": "Bochumer Linguistische"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Several types of machine learning algorithms have been successfully applied to these tasks, for example Hidden Markov Models (HMMs) (Kupiec 1992, Zhou and Su 2002), Support Vector Machines (SVMs) (Isozaki and Kazawa 2002, Gime\u0301nez and Ma\u0300rquez 2004, Chrupa la 2006), Memory-Based Learning (Daelemans et al. 1996, van den Bosch and Daelemans 1999, Tjong Kim Sang 2002b), etc.",
                "\u2026to these tasks, for example Hidden Markov Models (HMMs) (Kupiec 1992, Zhou and Su 2002), Support Vector Machines (SVMs) (Isozaki and Kazawa 2002, Gime\u0301nez and Ma\u0300rquez 2004, Chrupa la 2006), Memory-Based Learning (Daelemans et al. 1996, van den Bosch and Daelemans 1999, Tjong Kim Sang 2002b), etc."
            ],
            "citingPaper": {
                "paperId": "f035de9c8eab3eecc97313101decb19d21be4730",
                "externalIds": {
                    "CorpusId": 54036496
                },
                "url": "https://www.semanticscholar.org/paper/f035de9c8eab3eecc97313101decb19d21be4730",
                "title": "Preprocess : The multilingual LT 3 linguistic preprocessing toolkit",
                "abstract": "This paper presents the LeTs Preprocess Toolkit, a suite of robust high-performance preprocessing modules including Part-of-Speech Taggers, Lemmatizers and Named Entity Recognizers. The currently supported languages are Dutch, English, French and German. We give a detailed description of the architecture of the LeTs Preprocess pipeline and describe the data and methods used to train each component. Ten-fold cross-validation results are also presented. To assess the performance of each module on different domains, we collected real-world textual data from companies covering various domains (a.o. automotive, dredging and human resources) for all four supported languages. For this multi-domain corpus, a manually verified gold standard was created for each of the three preprocessing steps. We present the performance of our preprocessing components on this corpus and compare it to the performance of other existing tools.",
                "venue": "",
                "year": 2013,
                "referenceCount": 37,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "3230414",
                        "name": "M. Kauter"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background",
                "result"
            ],
            "contexts": [
                "When we compare these results against other POS tagging systems, we find, for instance, in Daelemans et al. (1996a) (which describes the MBT tagger that is also present in Frog) an accuracy of 97.1% for known words, 71.6% for unknown words and an overall accuracy (of known and unknown words\u2026",
                "Daelemans et al. (1996a) also mentions that the WOTAN tagger on the same corpus leads to an accuracy between 89.5% and 91.5% on newspaper articles."
            ],
            "citingPaper": {
                "paperId": "162fee246081ecd0c572a2c965e6e3b668f6c4b0",
                "externalIds": {
                    "MAG": "2156281647",
                    "CorpusId": 18267491
                },
                "url": "https://www.semanticscholar.org/paper/162fee246081ecd0c572a2c965e6e3b668f6c4b0",
                "title": "Developing a part-of-speech tagger for Dutch tweets",
                "abstract": "In this article we describe the design and creation of a part-of-speech tagger specifically for Dutch data from the popular microblogging service Twitter. Starting from the D-Coi part-of-speech tag set, which is also used in the SoNaR project, we added several Twitter-specific tags to allow the tagging of hashtags, @ mentions, emoticons and URLs. The tagger consists of the Frog tagger combined with a post-processing module that incorporates the new, Twitter-specific tags in the Frog part-of-speech output. Running the Frog tagger and the post-processing module sequentially leads to a part-of-speech tagger for Dutch tweets. Approximately 1 million tweets collected in the context of the SoNaR project were tagged by Frog and the post-processor combined. A sub-set of annotated tweets have been manually checked. Lastly, we evaluated the adapted part-of-speech tagger. \nThis project was accomplished by eight Master\u2019s students from Tilburg University, who had just completed a course in natural language processing. In addition to the theoretical knowledge they acquired during the course, this project, which took approximately a week, offered them hands-on experience.",
                "venue": "CLIN 2012",
                "year": 2012,
                "referenceCount": 30,
                "citationCount": 18,
                "influentialCitationCount": 2,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "3003885",
                        "name": "T. Avontuur"
                    },
                    {
                        "authorId": "1690669",
                        "name": "Iris Balemans"
                    },
                    {
                        "authorId": "72770533",
                        "name": "L. Elshof"
                    },
                    {
                        "authorId": "2101470",
                        "name": "N. V. Noord"
                    },
                    {
                        "authorId": "2066168",
                        "name": "M. Zaanen"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "This method is also referenced in the literature as similarity-based, example-based, memory-based, exemplar-based, case-based, analogical, nearest neighbor, and lazy learning (Daelemans et al., 1996).",
                "In the words of Daelemans et al. (1996), instance-based learning \u201cis a statistical approach, but it uses a different kind of statistics than Markov model-based approaches."
            ],
            "citingPaper": {
                "paperId": "1dda629dc6ba1982bb717ada0a350003102ca643",
                "externalIds": {
                    "MAG": "2105350750",
                    "CorpusId": 381137
                },
                "url": "https://www.semanticscholar.org/paper/1dda629dc6ba1982bb717ada0a350003102ca643",
                "title": "Modeling Relevance in Statistical Machine Translation: Scoring Alignment, Context, and Annotations of Translation Instances",
                "abstract": "Machine translation has advanced considerably in recent years, primarily due to the availability of larger datasets. However, one cannot rely on the availability of copious, high-quality bilingual training data. In this work, we improve upon the state-of-the-art in machine translation with an instance-based model that scores each instance of translation in the corpus. A translation instance reflects a source and target correspondence at one specific location in the corpus. The significance of this approach is that our model is able to capture that some instances of translation are more relevant than others. We have implemented this approach in Cunei, a new platform for machine translation that permits the scoring of instance-specific features. Leveraging per-instance alignment features, we demonstrate that Cunei can outperform Moses, a widely-used machine translation system. We then expand on this baseline system in three principal directions, each of which shows further gains. First, we score the source context of a translation instance in order to favor those that are most similar to the input sentence. Second, we apply similar techniques to score the target context of a translation instance and favor those that are most similar to the target hypothesis. Third, we provide a mechanism to mark-up the corpus with annotations (e.g. statistical word clustering, part-of-speech labels, and parse trees) and then exploit this information to create additional perinstance similarity features. Each of these techniques explicitly takes advantage of the fact that our approach scores each instance of translation on demand after the input sentence is provided and while the target hypothesis is being generated; similar extensions would be impossible or quite difficult in existing machine translation systems. Ultimately, this approach provides a more flexible framework for integration of novel features that adapts better to new data. In our experiments with German-English and Czech-English translation, the addition of instance-specific features consistently shows improvement.",
                "venue": "",
                "year": 2012,
                "referenceCount": 98,
                "citationCount": 6,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2450694",
                        "name": "Aaron B. Phillips"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "For all the POS tagging experiments, we use the memory-based POS tagger (MBT) (Daelemans et al., 1996) The best results, tuned on a dev set, were obtained, in nonexhaustive search, with the Modified Value Difference Metric as a distance metric and with k (the number of nearest neighbors) = 25.",
                "MBT: A memory-based part of speech tagger-generator."
            ],
            "citingPaper": {
                "paperId": "38969f57771f80400645e46f448e5f788331717d",
                "externalIds": {
                    "MAG": "2137397532",
                    "ACL": "P12-2035",
                    "DBLP": "conf/acl/MohamedMO12",
                    "CorpusId": 5980214
                },
                "url": "https://www.semanticscholar.org/paper/38969f57771f80400645e46f448e5f788331717d",
                "title": "Transforming Standard Arabic to Colloquial Arabic",
                "abstract": "We present a method for generating Colloquial Egyptian Arabic (CEA) from morphologically disambiguated Modern Standard Arabic (MSA). When used in POS tagging, this process improves the accuracy from 73.24% to 86.84% on unseen CEA text, and reduces the percentage of out-of-vocabulary words from 28.98% to 16.66%. The process holds promise for any NLP task targeting the dialectal varieties of Arabic; e.g., this approach may provide a cheap way to leverage MSA data and morphological resources to create resources for colloquial Arabic to English machine translation. It can also considerably speed up the annotation of Arabic dialects.",
                "venue": "ACL",
                "year": 2012,
                "referenceCount": 14,
                "citationCount": 19,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "144698421",
                        "name": "Emad Mohamed"
                    },
                    {
                        "authorId": "1809988",
                        "name": "B. Mohit"
                    },
                    {
                        "authorId": "1723120",
                        "name": "Kemal Oflazer"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "49f8320a558588931a462297d8846fbacf40e6b8",
                "externalIds": {
                    "MAG": "2138238723",
                    "DBLP": "series/synthesis/2012Piotrowski",
                    "DOI": "10.2200/S00436ED1V01Y201207HLT017",
                    "CorpusId": 58270562
                },
                "url": "https://www.semanticscholar.org/paper/49f8320a558588931a462297d8846fbacf40e6b8",
                "title": "Natural Language Processing for Historical Texts",
                "abstract": "More and more historical texts are becoming available in digital form. Digitization of paper documents is motivated by the aim of preserving cultural heritage and making it more accessible, both to laypeople and scholars. As digital images cannot be searched for text, digitization projects increasingly strive to create digital text, which can be searched and otherwise automatically processed, in addition to facsimiles. Indeed, the emerging field of digital humanities heavily relies on the availability of digital text for its studies. Together with the increasing availability of historical texts in digital form, there is a growing interest in applying natural language processing (NLP) methods and tools to historical texts. However, the specific linguistic properties of historical texts -- the lack of standardized orthography, in particular -- pose special challenges for NLP. This book aims to give an introduction to NLP for historical texts and an overview of the state of the art in this field. The book starts with an overview of methods for the acquisition of historical texts (scanning and OCR), discusses text encoding and annotation schemes, and presents examples of corpora of historical texts in a variety of languages. The book then discusses specific methods, such as creating part-of-speech taggers for historical languages or handling spelling variation. A final chapter analyzes the relationship between NLP and the digital humanities. Certain recently emerging textual genres, such as SMS, social media, and chat messages, or newsgroup and forum postings share a number of properties with historical texts, for example, nonstandard orthography and grammar, and profuse use of abbreviations. The methods and techniques required for the effective processing of historical texts are thus also of interest for research in other domains.",
                "venue": "Synthesis Lectures on Human Language Technologies",
                "year": 2012,
                "referenceCount": 140,
                "citationCount": 160,
                "influentialCitationCount": 12,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Art",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1955864",
                        "name": "M. Piotrowski"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "4a2a154ddce20525fe15e368b7a581ee520abe31",
                "externalIds": {
                    "MAG": "2341868106",
                    "CorpusId": 14164809
                },
                "url": "https://www.semanticscholar.org/paper/4a2a154ddce20525fe15e368b7a581ee520abe31",
                "title": "AUTOMATIC TEXT SUMMARIZATION BASED ON PRAGMATIC ANALYSIS",
                "abstract": "The rapid growth of online information has encumbered the user with colossal amount of information. It is difficult to access large amount of data. This problem has increased the research in the field of automatic text summarization. Automatic text summarization is a technique where the text is input to the computer and it returns the clipped and concise extract of the original text and also sustains the overall meaning and main information content. In this paper, text summarization technique is designed for the documents having the fixed format. The proposed system generates the summary of the fixed format documents by analyzing all the different parts of the documents. The system consists of five stages. In first stage each sentence is partitioned into the list of tokens and stop words are removed. In second stage, frequency usage is counted for each word. In third stage, assign POS tag for each weighted term and Word sense disambiguation is done. In the fourth stage, pragmatic analysis is performed. After Pragmatic Analysis, summarized sentences will be store in a database.",
                "venue": "",
                "year": 2012,
                "referenceCount": 17,
                "citationCount": 7,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "145390690",
                        "name": "M. Prabhakar"
                    },
                    {
                        "authorId": "49734588",
                        "name": "Nidhi Chandra"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "We use the Memory-Based Tagger (Daelemans et al., 1996) trained on the Brown corpus to compute the part-ofspeech tags."
            ],
            "citingPaper": {
                "paperId": "50dfb7358cc85cc7ab0eda68c517164ebd205d42",
                "externalIds": {
                    "MAG": "2156422881",
                    "DBLP": "conf/acl/WubbenBK12",
                    "ACL": "P12-1107",
                    "CorpusId": 141120
                },
                "url": "https://www.semanticscholar.org/paper/50dfb7358cc85cc7ab0eda68c517164ebd205d42",
                "title": "Sentence Simplification by Monolingual Machine Translation",
                "abstract": "In this paper we describe a method for simplifying sentences using Phrase Based Machine Translation, augmented with a re-ranking heuristic based on dissimilarity, and trained on a monolingual parallel corpus. We compare our system to a word-substitution baseline and two state-of-the-art systems, all trained and tested on paired sentences from the English part of Wikipedia and Simple Wikipedia. Human test subjects judge the output of the different systems. Analysing the judgements shows that by relatively careful phrase-based paraphrasing our model achieves similar simplification results to state-of-the-art systems, while generating better formed output. We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems.",
                "venue": "ACL",
                "year": 2012,
                "referenceCount": 39,
                "citationCount": 258,
                "influentialCitationCount": 40,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1917518",
                        "name": "S. Wubben"
                    },
                    {
                        "authorId": "145977875",
                        "name": "Antal van den Bosch"
                    },
                    {
                        "authorId": "145210073",
                        "name": "E. Krahmer"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Der Gebrauch von Lernverfahren, die besser mit spa\u0308rlichen Daten zurechtkommen, etwa k-n\u0308achste-Nachbarn-Klassifikatoren (wie sie Daelemans et al. (1996) fu\u0308rs POS-Tagging benutzen) scheint bei dieser Datenmenge aufgrund der la\u0308ng ren Rechenzeit nicht sinnvoll."
            ],
            "citingPaper": {
                "paperId": "5f0c20a3fd4e68afc151547027e3bcd59bc87934",
                "externalIds": {
                    "MAG": "2886903088",
                    "CorpusId": 165231319
                },
                "url": "https://www.semanticscholar.org/paper/5f0c20a3fd4e68afc151547027e3bcd59bc87934",
                "title": "Tagging kausaler Relationen",
                "abstract": "Inhaltlich unveranderte Neuauflage. In diesem Buch geht es um kausale Beziehungen zwischen Ereignissen und Erklarungsbeziehungen zwischen Ereignissen, bei denen kausale Relationen eine wichtige Rolle spielen. Neben zeitlichen Relationen, die wegen ihrer einfacheren Formalisierbarkeit und andererseits ihrer gut sichtbaren Rolle in der Grammatik (Tempus und Aspekt, zeitliche Konjunktionen) standen, und Koreferenzrelationen zwischen Nennungen einer Entitat haben kausale Beziehungen und die Erklarungen, die sie ermoglichen, eine wichtige Rolle im Koharenzgefuge des Textes. Im Gegensatz zu \"tiefen\" Verfahren, die auf einer detaillierten semantischen Reprasentation des Textes aufsetzen und infolgedessen fur unrestringierten Text nicht immer geeignet sind, wird hier untersucht, wie man dieses Ziel erreichen kann, ohne sich auf eine aufwandig konstruierte Wissensbasis verlassen zu mussen.",
                "venue": "",
                "year": 2012,
                "referenceCount": 98,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Philosophy"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Philosophy",
                        "source": "external"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2232237",
                        "name": "Yannick Versley"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "As automatic tagger we used MBT (Daelemans et al., 1996), a memory-based tagger.",
                "As MBT has features and parameters to be set, we ran ten-fold cross-validation experiments on the training set for finding a suitable setting.",
                "To estimate the performance of MBT, we ran some experiments on the adapted CINTIL corpus and compared MBT against another POS-tagger for Portuguese, the LX-tagger (?).",
                "On the test set of 86K tokens, MBT obtained a F-score of 95.42 against 93.92 F-score for the LX-tagger."
            ],
            "citingPaper": {
                "paperId": "61795dd562f2e28103c57ffece902a0b24eb5f2d",
                "externalIds": {
                    "CorpusId": 201721214
                },
                "url": "https://www.semanticscholar.org/paper/61795dd562f2e28103c57ffece902a0b24eb5f2d",
                "title": "Introducing the Reference Corpus of Contemporary Portuguese",
                "abstract": "We present our work in processing a Portuguese corpus and its publication online. After discussing how the corpus was built and our choice of meta-data, we turn to the processes and tools involved for the cleaning, preparation and annotation to make the corpus suitable for linguistic inquiries. The Web platform is described, and we show examples of linguistic resources that can be extracted from the platform for use in linguistic studies or in NLP.",
                "venue": "",
                "year": 2012,
                "referenceCount": 12,
                "citationCount": 4,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2761749",
                        "name": "M. G\u00e9n\u00e9reux"
                    },
                    {
                        "authorId": "73422065",
                        "name": "I. Hendrickx"
                    },
                    {
                        "authorId": "3137052",
                        "name": "Am\u00e1lia Mendes"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "These documents were subsequently split into sentences using the MBT parser which was adapted for biomedical texts [25]."
            ],
            "citingPaper": {
                "paperId": "744936965fa245be48e4bca173d939e2949f63e4",
                "externalIds": {
                    "DBLP": "journals/bmcbi/VeutheyBGRMBX13",
                    "PubMedCentral": "3660268",
                    "MAG": "2144133357",
                    "DOI": "10.1186/1471-2105-14-104",
                    "CorpusId": 8970627,
                    "PubMed": "23517090"
                },
                "url": "https://www.semanticscholar.org/paper/744936965fa245be48e4bca173d939e2949f63e4",
                "title": "Application of text-mining for updating protein post-translational modification annotation in UniProtKB",
                "abstract": "BackgroundThe annotation of protein post-translational modifications (PTMs) is an important task of UniProtKB curators and, with continuing improvements in experimental methodology, an ever greater number of articles are being published on this topic. To help curators cope with this growing body of information we have developed a system which extracts information from the scientific literature for the most frequently annotated PTMs in UniProtKB.ResultsThe procedure uses a pattern-matching and rule-based approach to extract sentences with information on the type and site of modification. A ranked list of protein candidates for the modification is also provided. For PTM extraction, precision varies from 57% to 94%, and recall from 75% to 95%, according to the type of modification. The procedure was used to track new publications on PTMs and to recover potential supporting evidence for phosphorylation sites annotated based on the results of large scale proteomics experiments.ConclusionsThe information retrieval and extraction method we have developed in this study forms the basis of a simple tool for the manual curation of protein post-translational modifications in UniProtKB/Swiss-Prot. Our work demonstrates that even simple text-mining tools can be effectively adapted for database curation tasks, providing that a thorough understanding of the working process and requirements are first obtained. This system can be accessed at http://eagl.unige.ch/PTM/.",
                "venue": "BMC Bioinformatics",
                "year": 2013,
                "referenceCount": 33,
                "citationCount": 19,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science",
                    "Medicine"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Medicine",
                        "source": "external"
                    },
                    {
                        "category": "Biology",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2070787",
                        "name": "A. Veuthey"
                    },
                    {
                        "authorId": "145718058",
                        "name": "A. Bridge"
                    },
                    {
                        "authorId": "1692362",
                        "name": "J. Gobeill"
                    },
                    {
                        "authorId": "1724346",
                        "name": "P. Ruch"
                    },
                    {
                        "authorId": "38825933",
                        "name": "J. Mcentyre"
                    },
                    {
                        "authorId": "31613661",
                        "name": "L. Bougueleret"
                    },
                    {
                        "authorId": "1793133",
                        "name": "I. Xenarios"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "\u2026BulTreeBank:2 TreeTagger (Schmid, 1994), which uses decision trees, TnT (Brants, 2000), which uses a hidden Markov model, SVMtool (Gime\u0301nez and Ma\u0300rquez, 2004), which is based on support vector machines, and ACOPOST (Schro\u0308der, 2002), implementing the memory-based model of Daelemans et al. (1996)."
            ],
            "citingPaper": {
                "paperId": "8f95c814fb274b286c1dd2ba3bd9c72c998e34c2",
                "externalIds": {
                    "ACL": "E12-1050",
                    "DBLP": "conf/eacl/GeorgievZSON12",
                    "MAG": "2991144948",
                    "ArXiv": "1911.11503",
                    "CorpusId": 5728098
                },
                "url": "https://www.semanticscholar.org/paper/8f95c814fb274b286c1dd2ba3bd9c72c998e34c2",
                "title": "Feature-Rich Part-of-speech Tagging for Morphologically Complex Languages: Application to Bulgarian",
                "abstract": "We present experiments with part-of-speech tagging for Bulgarian, a Slavic language with rich inflectional and derivational morphology. Unlike most previous work, which has used a small number of grammatical categories, we work with 680 morpho-syntactic tags. We combine a large morphological lexicon with prior linguistic knowledge and guided learning from a POS-annotated corpus, achieving accuracy of 97.98%, which is a significant improvement over the state-of-the-art for Bulgarian.",
                "venue": "EACL",
                "year": 2012,
                "referenceCount": 49,
                "citationCount": 33,
                "influentialCitationCount": 2,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2065303524",
                        "name": "Georgi Georgiev"
                    },
                    {
                        "authorId": "2138716",
                        "name": "Valentin Zhikov"
                    },
                    {
                        "authorId": "143964258",
                        "name": "K. Simov"
                    },
                    {
                        "authorId": "1710801",
                        "name": "P. Osenova"
                    },
                    {
                        "authorId": "1683562",
                        "name": "Preslav Nakov"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "The set of taggers was later on (Tachbelie et al., 2011) extended with MBT, a Memory-Based Learning tagger (Daelemans et al., 1996), and a CRF-based tagger developed in the toolkit CRF++ (Lafferty et al., 2001).",
                ", 2011) extended with MBT, a Memory-Based Learning tagger (Daelemans et al., 1996), and a CRF-based tagger developed in the toolkit CRF++ (Lafferty et al."
            ],
            "citingPaper": {
                "paperId": "92923003c79ebc3d8b8d66fea1c7d9f2088aa4c0",
                "externalIds": {
                    "CorpusId": 3908293
                },
                "url": "https://www.semanticscholar.org/paper/92923003c79ebc3d8b8d66fea1c7d9f2088aa4c0",
                "title": "Tagging and Verifying an Amharic News Corpus",
                "abstract": "The paper describes work on verifying, correcting and retagging a corpus of Amharic news texts. A total of 8715 Amharic news articles had previously been collected from a web site, and part of the corpus (1065 articles; 210,000 words) then morphologically analysed and manually part-of-speech tagged. The tagged corpus has been used as the basis for testing the application to Amharic of machine learning techniques and tools developed for other languages. This process made it possible to spot several errors and inconsistencies in the corpus which has been iteratively refined, cleaned, normalised, split into folds, and partially re-tagged by both automatic and manual means.",
                "venue": "",
                "year": 2012,
                "referenceCount": 25,
                "citationCount": 9,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1887897",
                        "name": "Bj\u00f6rn Gamb\u00e4ck"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "ad91743d1045fa31cde853df473a8a2dedad84ac",
                "externalIds": {
                    "MAG": "2576317465",
                    "CorpusId": 63279467
                },
                "url": "https://www.semanticscholar.org/paper/ad91743d1045fa31cde853df473a8a2dedad84ac",
                "title": "Proceedings of the workshop on language technology for normalisation of less-resourced languages (SaLTMiL 8 - AfLaT 2012)",
                "abstract": "This paper describes the stages involved in implementing a corpus of spoken Irish. This pilot project (consisting of approximately 140K words of transcribed data) implements part of the design of a larger corpus of spoken Irish which it is hoped will contain approximately 2 million words when complete. It hoped that such a corpus will provide material for linguistic research, lexicography, the teaching of Irish and for development of language technology for the Irish language.",
                "venue": "",
                "year": 2012,
                "referenceCount": 250,
                "citationCount": 2,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1807619",
                        "name": "G. Pauw"
                    },
                    {
                        "authorId": "46183566",
                        "name": "G. D. Schryver"
                    },
                    {
                        "authorId": "2586725",
                        "name": "M. Forcada"
                    },
                    {
                        "authorId": "2066464",
                        "name": "K. Sarasola"
                    },
                    {
                        "authorId": "3262036",
                        "name": "Francis M. Tyers"
                    },
                    {
                        "authorId": "2875859",
                        "name": "P. Wagacha"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "We can observe that MBT outperforms the LX-tagger and therefore we used MBT to tag the full corpus.",
                "MBT splits the data in two categories: known and unknown words.",
                "As MBT has features and parameters to be set, we ran ten-fold cross-validation experiments on the training set for finding a suitable setting.",
                "For the known words, MBT achieves an accuracy of 96% on the test set while for the small subset of unknown words (5,664 tokens), it has an accuracy of 88.2%.",
                "We compared MBT [10], a memorybased tagger to the LX-tagger [7].",
                "The most frequent errors that are made by MBT match the type of decisions that are also difficult for humans to make such as distinguishing if the word \u201cque\u201d is a relative or a conjunction, and if a word like \u201citaliano\u201d is a common noun or an adjective."
            ],
            "citingPaper": {
                "paperId": "d325a7a491a1932f1d37248907366d8a5902e6c5",
                "externalIds": {
                    "DBLP": "conf/propor/GenereuxHM12",
                    "MAG": "2152674344",
                    "DOI": "10.1007/978-3-642-28885-2_13",
                    "CorpusId": 15695534
                },
                "url": "https://www.semanticscholar.org/paper/d325a7a491a1932f1d37248907366d8a5902e6c5",
                "title": "A Large Portuguese Corpus On-Line: Cleaning and Preprocessing",
                "abstract": "We present a newly available on-line resource for Portuguese, a corpus of 310 million words, a new version of the Reference Corpus of Contemporary Portuguese, now searchable via a user-friendly web interface. Here we report on work carried out on the corpus previous to its publication on-line. We focus on the processes and tools involved for the cleaning, preparation and annotation to make the corpus suitable for linguistic inquiries.",
                "venue": "PROPOR",
                "year": 2012,
                "referenceCount": 19,
                "citationCount": 10,
                "influentialCitationCount": 0,
                "isOpenAccess": true,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2761749",
                        "name": "M. G\u00e9n\u00e9reux"
                    },
                    {
                        "authorId": "1708288",
                        "name": "Iris Hendrickx"
                    },
                    {
                        "authorId": "3137052",
                        "name": "Am\u00e1lia Mendes"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "e48ad35311acd98edef682f4658ef2baeb79a6ae",
                "externalIds": {
                    "MAG": "2327357558",
                    "CorpusId": 17642068
                },
                "url": "https://www.semanticscholar.org/paper/e48ad35311acd98edef682f4658ef2baeb79a6ae",
                "title": "Natural Language Processing for Amazigh Language: Challenges and Future Directions",
                "abstract": "Amazigh language, as one of the indo-European languages, poses many challenges on natural language pro cessing. The writing system, the morphology based on unique word formation process of roots and patterns, and the lack of linguisti c corpora make computational approaches to Amazigh language challenging. In this paper, we give an overview of the current s tate of the art in Natural Language Processing for Amazigh language in Morocco, and we suggest the development of other technologies ne eded for the Amazigh language to live in \"informati on society\".",
                "venue": "",
                "year": 2012,
                "referenceCount": 264,
                "citationCount": 10,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "10807048",
                        "name": "Ataa Allah Fadoua"
                    },
                    {
                        "authorId": "118265323",
                        "name": "Boulaknadel Siham"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "ef057dfa786877fa15c1818ada23096c78c85273",
                "externalIds": {
                    "ACL": "L12-1143",
                    "DBLP": "conf/lrec/GenereuxHM12",
                    "MAG": "2251673411",
                    "CorpusId": 18606028
                },
                "url": "https://www.semanticscholar.org/paper/ef057dfa786877fa15c1818ada23096c78c85273",
                "title": "Introducing the Reference Corpus of Contemporary Portuguese Online",
                "abstract": "We present our work in processing the Reference Corpus of Contemporary Portuguese and its publication online. After discussing how the corpus was built and our choice of meta-data, we turn to the processes and tools involved for the cleaning, preparation and annotation to make the corpus suitable for linguistic inquiries. The Web platform is described, and we show examples of linguistic resources that can be extracted from the platform for use in linguistic studies or in NLP.",
                "venue": "LREC",
                "year": 2012,
                "referenceCount": 31,
                "citationCount": 7,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2761749",
                        "name": "M. G\u00e9n\u00e9reux"
                    },
                    {
                        "authorId": "1708288",
                        "name": "Iris Hendrickx"
                    },
                    {
                        "authorId": "3137052",
                        "name": "Am\u00e1lia Mendes"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "For POS tagging, we use MBT, a memory-based tagger (Daelemans et al. 1996)."
            ],
            "citingPaper": {
                "paperId": "1a5e0f5e36e3f1d4e3dfc3653671a8aa1b55ee74",
                "externalIds": {
                    "MAG": "2130167565",
                    "DBLP": "journals/nle/KublerM12",
                    "DOI": "10.1017/S1351324911000325",
                    "CorpusId": 41192054
                },
                "url": "https://www.semanticscholar.org/paper/1a5e0f5e36e3f1d4e3dfc3653671a8aa1b55ee74",
                "title": "Part of speech tagging for Arabic",
                "abstract": "Abstract This paper presents an investigation of part of speech (POS) tagging for Arabic as it occurs naturally, i.e. unvocalized text (without diacritics). We also do not assume any prior tokenization, although this was used previously as a basis for POS tagging. Arabic is a morphologically complex language, i.e. there is a high number of inflections per word; and the tagset is larger than the typical tagset for English. Both factors, the second one being partly dependent on the first, increase the number of word/tag combinations, for which the POS tagger needs to find estimates, and thus they contribute to data sparseness. We present a novel approach to Arabic POS tagging that does not require any pre-processing, such as segmentation or tokenization: whole word tagging. In this approach, the complete word is assigned a complex POS tag, which includes morphological information. A competing approach investigates the effect of segmentation and vocalization on POS tagging to alleviate data sparseness and ambiguity. In the segmentation-based approach, we first automatically segment words and then POS tags the segments. The complex tagset encompasses 993 POS tags, whereas the segment-based tagset encompasses only 139 tags. However, segments are also more ambiguous, thus there are more possible combinations of segment tags. In realistic situations, in which we have no information about segmentation or vocalization, whole word tagging reaches the highest accuracy of 94.74%. If gold standard segmentation or vocalization is available, including this information improves POS tagging accuracy. However, while our automatic segmentation and vocalization modules reach state-of-the-art performance, their performance is not reliable enough for POS tagging and actually impairs POS tagging performance. Finally, we investigate whether a reduction of the complex tagset to the Extra-Reduced Tagset as suggested by Habash and Rambow (Habash, N., and Rambow, O. 2005. Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), Ann Arbor, MI, USA, pp. 573\u201380) will alleviate the data sparseness problem. While the POS tagging accuracy increases due to the smaller tagset, a closer look shows that using a complex tagset for POS tagging and then converting the resulting annotation to the smaller tagset results in a higher accuracy than tagging using the smaller tagset directly.",
                "venue": "Natural Language Engineering",
                "year": 2011,
                "referenceCount": 66,
                "citationCount": 15,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1804668",
                        "name": "Sandra K\u00fcbler"
                    },
                    {
                        "authorId": "144698421",
                        "name": "Emad Mohamed"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "\u2026kNN ranks among the best performing techniques (Yang and Chute, 1994; Sebastiani, 2002), probability estimation for statistical parsing (Hogan, 2007), tagging (Daelemans et al., 1996), information extraction (Zavrel and Daelemans, 2003), and speech synthesis (Daelemans and van den Bosch, 1996)."
            ],
            "citingPaper": {
                "paperId": "1b40520704fd63a25eae2942a7ce59bf50b93f75",
                "externalIds": {
                    "MAG": "31783377",
                    "CorpusId": 59788064
                },
                "url": "https://www.semanticscholar.org/paper/1b40520704fd63a25eae2942a7ce59bf50b93f75",
                "title": "Machine Learning for Natural Language Processing",
                "abstract": "Over the past decade Machine Learning techniques has become an essentialtool for Natural Language Processing. This introductory course will coverthe basics of Machine Learning and present a selection of widely used al-gorithms, illustrating them with practical applications to Natural LanguageProcessing. The course will start with a survey of the main concepts inMachine Learning, in terms of the main decisions one needs to make whendesigning a Machine Learning application, including: type of training (su-pervised, unsupervised, active learning etc), data representation, choice andrepresentation of target function, choice of learning algorithm. This will befollowed by case studies designed to illustrate practical applications of theseconcepts. Unsupervised learning techniques (clustering) will be describedand illustrated through applications to tasks such as thesaurus induction,document class inference, and term extraction for text classi\ufb01cation. Super-vised learning techniques covering symbolic (e.g. decision trees) and non-symbolic approaches (e.g. probabilistic classi\ufb01ers, instance-based classi\ufb01ers,support vector machines) will be presented and case studies on text clas-si\ufb01cation and word sense disambiguation analysed in some detail. Finally,we will address the issue of learning target functions which assign struc-tures to linear sequences covering applications of Hidden Markov Modelsto part-of-speech tagging and Probabilistic Grammars to parsing of naturallanguage.",
                "venue": "",
                "year": 2011,
                "referenceCount": 87,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2778174",
                        "name": "M. Emms"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Some typical methods in this family are neural networks [5], maximum entropy models [6] [7], conditional random field (CRF) [8], hidden Markov models (HMM) [9] [10], the Markov family models [11], memory\u00ad based learning [12], and decision trees [13] [14]."
            ],
            "citingPaper": {
                "paperId": "2825ce5bc458e83b6f10bae14b9d9a5fd44f5d05",
                "externalIds": {
                    "MAG": "2534443876",
                    "DBLP": "conf/nlpke/MaLHS11",
                    "DOI": "10.1109/NLPKE.2011.6138191",
                    "CorpusId": 17659594
                },
                "url": "https://www.semanticscholar.org/paper/2825ce5bc458e83b6f10bae14b9d9a5fd44f5d05",
                "title": "An English part-of-speech tagger for machine translation in business domain",
                "abstract": "Part-of-speech tagging is a crucial preprocessing step for machine translation. Current studies mainly focus on the methods, linguistic, statistic, machine learning or hybrid. But so far not many serious attempts have been performed to test the reported accuracy of taggers on different, perhaps domain-specific, corpora. Therefore, this paper presents an English POS tagger for English-Chinese machine translation in business domain, demonstrating how a present tagger can be adapted to learn from a small amount of data and handle unknown words for the purpose of machine translation. A small size of 998k English annotated corpus in business domain is built semi-automatically based on a new tagset, the maximum entropy model is adopted and rule-based approach is used in post-processing. Experiments show that our tagger achieves an accuracy of 99.08% in closed test and 98.14% in open test, which is a quite satisfactory result, compared with the reported best open test result of 97.18% of Stanford English tagger.",
                "venue": "2011 7th International Conference on Natural Language Processing and Knowledge Engineering",
                "year": 2011,
                "referenceCount": 22,
                "citationCount": 3,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2146392731",
                        "name": "Jianjun Ma"
                    },
                    {
                        "authorId": "2109526752",
                        "name": "Haixia Liu"
                    },
                    {
                        "authorId": "2610330",
                        "name": "Degen Huang"
                    },
                    {
                        "authorId": "39793118",
                        "name": "Wenfeng Sheng"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "2870870f0e7fec27dc28fde0b3bd41c4550b1a86",
                "externalIds": {
                    "MAG": "2621900088",
                    "CorpusId": 64470759
                },
                "url": "https://www.semanticscholar.org/paper/2870870f0e7fec27dc28fde0b3bd41c4550b1a86",
                "title": "Part-of-Speech Tagging for Under-Resourced and Morphologically Rich Languages - The Case of Amharic",
                "abstract": "This paper presents part-of-speech (POS) tagging experiments conducted to identify the best method for under-resourced and morphologically rich languages. The experiments have been conducted using different tagging strategies and different training data sizes for Amharic. Experiments on word segmentation and tag hypotheses combination have also been conducted to improve tagging accuracy. The results showed that methods like MBT are good for under-resourced languages. Moreover, segmenting words composed of morphemes of different POS tags and tag hypotheses combination are promising directions to improve tagging performance for under-resourced and morphologically rich languages.",
                "venue": "",
                "year": 2011,
                "referenceCount": 15,
                "citationCount": 24,
                "influentialCitationCount": 2,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2173279",
                        "name": "Martha Yifiru Tachbelie"
                    },
                    {
                        "authorId": "35053899",
                        "name": "S. Abate"
                    },
                    {
                        "authorId": "143823463",
                        "name": "L. Besacier"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "2a6626dadb6b624011c39270cc7678ac98e162a3",
                "externalIds": {
                    "ACL": "P11-2009",
                    "MAG": "2137845336",
                    "DBLP": "conf/acl/Sogaard11",
                    "CorpusId": 28873816
                },
                "url": "https://www.semanticscholar.org/paper/2a6626dadb6b624011c39270cc7678ac98e162a3",
                "title": "Semi-supervised condensed nearest neighbor for part-of-speech tagging",
                "abstract": "This paper introduces a new training set condensation technique designed for mixtures of labeled and unlabeled data. It finds a condensed set of labeled and unlabeled data points, typically smaller than what is obtained using condensed nearest neighbor on the labeled data only, and improves classification accuracy. We evaluate the algorithm on semi-supervised part-of-speech tagging and present the best published result on the Wall Street Journal data set.",
                "venue": "ACL",
                "year": 2011,
                "referenceCount": 22,
                "citationCount": 66,
                "influentialCitationCount": 9,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1700187",
                        "name": "Anders S\u00f8gaard"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "49d00a40713100a80e5d8fb697bda194c93df0e0",
                "externalIds": {
                    "DBLP": "journals/ijait/OrtegaTGVC11",
                    "MAG": "1984216093",
                    "DOI": "10.1142/S0218213011000437",
                    "CorpusId": 207135114
                },
                "url": "https://www.semanticscholar.org/paper/49d00a40713100a80e5d8fb697bda194c93df0e0",
                "title": "Str: a Graph-Based Tagging Technique",
                "abstract": "This paper presents the ideas, experiments and specifications related to the Supervised TextRank (STR) technique, a word tagging method based on the TextRank algorithm. The main innovation of STR technique is the use of a graph-based ranking algorithm similar to PageRank in a supervised fashion, gathering the information needed to build the graph representations of the text from a tagged corpus. We also propose a flexible graph specification language that allows to easily experiment with multiple configurations for the topology of the graph and for the information associated to the nodes and the edges. We have carried experiments in the Part-Of-Speech task, a common tagging problem in Natural Language Processing. In our best result we have achieved a precision of 96.16%, at the same level of the best tagging tools.",
                "venue": "Int. J. Artif. Intell. Tools",
                "year": 2011,
                "referenceCount": 22,
                "citationCount": 1,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "31784512",
                        "name": "F. J. Ortega"
                    },
                    {
                        "authorId": "2944410",
                        "name": "J. Jim\u00e9nez"
                    },
                    {
                        "authorId": "2072215569",
                        "name": "F. J. Gal\u00e1n"
                    },
                    {
                        "authorId": "47333842",
                        "name": "Carlos G. Vallejo"
                    },
                    {
                        "authorId": "143900195",
                        "name": "F. Cruz"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Three tools designed for this task have been used as base classifiers: TnT [1] 1 , TreeTagger [8] 2 and MBT [ 3 ] 3 , adding a fourth classifier based on features and implemented using the software SV M light [6] 4 . The combination methods implemented are: Bayes (BAY), Behavior Knowledge Space (BKS), Stacked Generalization (SG), simple probabilistic combination (SPC), voting (VT) and bagging (BAG)."
            ],
            "citingPaper": {
                "paperId": "6ab683893894348df510eb7945849ccca4bf1b7b",
                "externalIds": {
                    "DBLP": "conf/nldb/EnriquezTCO11",
                    "MAG": "326527976",
                    "DOI": "10.1007/978-3-642-22327-3_33",
                    "CorpusId": 40471082
                },
                "url": "https://www.semanticscholar.org/paper/6ab683893894348df510eb7945849ccca4bf1b7b",
                "title": "A Comparative Study of Classifier Combination Methods Applied to NLP Tasks",
                "abstract": "There are many classification tools that can be used for various NLP tasks, although none of them can be considered the best of all since each one has a particular list of virtues and defects. The combination methods can serve both to maximize the strengths of the base classifiers and to reduce errors caused by their defects improving the results in terms of accuracy. Here is a comparative study on the most relevant methods that shows that combination seems to be a robust and reliable way of improving our results.",
                "venue": "NLDB",
                "year": 2011,
                "referenceCount": 8,
                "citationCount": 3,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "12266907",
                        "name": "Fernando Enr\u00edquez"
                    },
                    {
                        "authorId": "2944410",
                        "name": "J. Jim\u00e9nez"
                    },
                    {
                        "authorId": "143900195",
                        "name": "F. Cruz"
                    },
                    {
                        "authorId": "31784512",
                        "name": "F. J. Ortega"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "6cf74ec968255aa0ff0cafb2702eb3dde1b21fb6",
                "externalIds": {
                    "MAG": "2125544673",
                    "CorpusId": 61165451
                },
                "url": "https://www.semanticscholar.org/paper/6cf74ec968255aa0ff0cafb2702eb3dde1b21fb6",
                "title": "Paraphrasing Headlines by Machine Translation Sentential Paraphrase Acquisition and Generation using Google News",
                "abstract": null,
                "venue": "",
                "year": 2011,
                "referenceCount": 24,
                "citationCount": 9,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1917518",
                        "name": "S. Wubben"
                    },
                    {
                        "authorId": "145977875",
                        "name": "Antal van den Bosch"
                    },
                    {
                        "authorId": "145210073",
                        "name": "E. Krahmer"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "9d325ecc09c06d0364843ed75b2a82df52cb231c",
                "externalIds": {
                    "DBLP": "phd/ndltd/Domingues11a",
                    "MAG": "12295126",
                    "CorpusId": 37279470
                },
                "url": "https://www.semanticscholar.org/paper/9d325ecc09c06d0364843ed75b2a82df52cb231c",
                "title": "Abordagem para o desenvolvimento de um etiquetador de alta acur\u00e1cia para o Portugu\u00eas do Brasil",
                "abstract": null,
                "venue": "",
                "year": 2011,
                "referenceCount": 54,
                "citationCount": 3,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    }
                ],
                "authors": [
                    {
                        "authorId": "22524716",
                        "name": "Miriam L\u00facia Campos Serra Domingues"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "b5a35ebbc8d890dbfe82e46d53bfa14a5f157ed7",
                "externalIds": {
                    "MAG": "2130488532",
                    "CorpusId": 57182642
                },
                "url": "https://www.semanticscholar.org/paper/b5a35ebbc8d890dbfe82e46d53bfa14a5f157ed7",
                "title": "Statistical langauge models for alternative sequence selection",
                "abstract": "Users may download and print one copy of any publication from the public portal for the purpose of private study or research You may not further distribute the material or use it for any profit-making activity or commercial gain You may freely distribute the URL identifying the publication in the public portal Take down policy If you believe that this document breaches copyright, please contact us providing details, and we will remove access to the work immediately and investigate your claim.",
                "venue": "",
                "year": 2011,
                "referenceCount": 224,
                "citationCount": 79,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Economics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2243741",
                        "name": "H. Stehouwer"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "b7827ac13ece48573b8ae04fb4574f5e87327300",
                "externalIds": {
                    "CorpusId": 212523207
                },
                "url": "https://www.semanticscholar.org/paper/b7827ac13ece48573b8ae04fb4574f5e87327300",
                "title": "Corpus based Automatic Text Summarization System with HMM Tagger",
                "abstract": "118 \uf020 Abstract\u2014The rapid growth of the data in the Internet has overloaded the user with enormous amounts of information which is more difficult to access huge volumes of documents. Automatic text summarization technique is an important activity in the analysis of high volume text documents. Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning. In this paper a frequent term based text summarization technique with HMM tagger is designed and implemented in java. The proposed system generates a summary for a given input document based on identification and extraction of important sentences in the document. The model consists of four stages. In first stage, the system decomposes the given text into its constituent sentences, assigning the POS (tag) for each word in the text and stores the result in a table. The second stage removes the stop words, stemming the text and applying lemmatization. Feature term identification is done in third stage. Finally each sentence is ranked depending on feature terms. This stage reduced the amount of the sentences in the summary in order to produce a qualitative summary.",
                "venue": "",
                "year": 2011,
                "referenceCount": 21,
                "citationCount": 9,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "48684816",
                        "name": "M. Suneetha"
                    },
                    {
                        "authorId": "145199061",
                        "name": "S. Fatima"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "c24f9af523f2091974967ffb9ef645d1c6df802a",
                "externalIds": {
                    "ACL": "2011.mtsummit-papers.4",
                    "DBLP": "conf/mtsummit/MaHLS11",
                    "CorpusId": 37892600
                },
                "url": "https://www.semanticscholar.org/paper/c24f9af523f2091974967ffb9ef645d1c6df802a",
                "title": "POS Tagging of English Particles for Machine Translation",
                "abstract": "Part-of-speech tagging is a crucial preprocessing step for machine translation. Ambiguity in the natural language processing has made POS tagging hard. And particles are a major cause of ambiguity. But current studies have limited particles in narrow sense. Therefore, this study presents an English POS tagger basically addressing the tagging of particles in broad sense. A definition of particles in broad sense is given, a small size of 998k English annotated corpus in business domain is built, the maximum entropy model is adopted and rulebased approach is used in post-processing. Experiments show that our tagger achieves an F-score of 90.87% in closed test and 87.24% in open test, which is a quite satisfactory result.",
                "venue": "MTSUMMIT",
                "year": 2011,
                "referenceCount": 23,
                "citationCount": 5,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2146392731",
                        "name": "Jianjun Ma"
                    },
                    {
                        "authorId": "2610330",
                        "name": "Degen Huang"
                    },
                    {
                        "authorId": "2109526752",
                        "name": "Haixia Liu"
                    },
                    {
                        "authorId": "39793118",
                        "name": "Wenfeng Sheng"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "e69cbbe03fdeec3071b0fb1012612aa8c7abaa80",
                "externalIds": {
                    "MAG": "1599518318",
                    "CorpusId": 60929881
                },
                "url": "https://www.semanticscholar.org/paper/e69cbbe03fdeec3071b0fb1012612aa8c7abaa80",
                "title": "Development of shahmukhi to gurmukhi transliteration system",
                "abstract": null,
                "venue": "",
                "year": 2011,
                "referenceCount": 155,
                "citationCount": 0,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    }
                ],
                "authors": [
                    {
                        "authorId": "153805599",
                        "name": "T. Singh"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "f470e71bd3b6f6999ea22c86e3d4d83e785005be",
                "externalIds": {
                    "MAG": "1550965316",
                    "CorpusId": 194352494
                },
                "url": "https://www.semanticscholar.org/paper/f470e71bd3b6f6999ea22c86e3d4d83e785005be",
                "title": "Domain adaptation for parsing",
                "abstract": "Het doel van de computationele taalkunde is het maken van systemen die in staat zijn natuurlijke taal te begrijpen en te produceren, net zoals wij mensen dat doen. Het maken van dergelijke systemen is moeilijk, onder andere vanwege het probleem van de ambiguiteit van natuurlijke taal. In dit proefschrift ligt de focus op het automatisch ontleden, het bepalen van welke woorden en woordgroepen bij elkaar horen, en wat de functie van de verschillende woordgroepen is. Het probleem van ambiguiteit doet zich ook hier voor omdat er vaak meerdere ontledingen bestaan voor een uiting. Om het probleem van ambiguiteit aan te pakken wordt veelal gebruik gemaakt van machinaal leren. Een model wordt geleerd door parameters te berekenen op basis van soms wel duizenden kenmerken van de trainingdata. Die trainingdata bestaat uit duizenden zinnen waarvoor de correcte ontleding handmatig is vastgelegd. Het blijkt dat deze aanpak voor het automatisch ontleden goede resultaten geeft zolang de trainingdata representatief is. Dus, als de trainingdata bestaat uit krantenartikelen uit de Volkskrant dan zal het resulterende model vooral goede prestaties halen op andere krantenartikelen uit de Volkskrant. Maar als we dat model toepassen op bijvoorbeeld een wetenschappelijk essay over oceanografie, dan worden de prestaties snel veel minder. Automatische ontleedsystemen zijn dus sterk afhankelijk van het domein van de teksten waaruit de trainingdata is opgebouwd. Dit proefschrift onderzoekt de domeinafhankelijkheid van automatische ontleedsystemen. De belangrijkste bijdragen van dit proefschrift zijn de volgende. Na een inleiding in het automatisch ontleden en het probleem van domeinafhankelijkheid onderzoeken we in het tweede deel van dit proefschrift de effectiviteit van nieuwe en bestaande algoritmes voor het aanpassen van modellen aan andere domeinen. Deze worden geevalueerd in het kader van een automatisch ontleedsysteem voor het Nederlands dat gebaseerd is op een handgeschreven grammatica, de Alpino parser. Eerder werk was gericht op domeinafhankelijkheid van ontleedsystemen die in zijn geheel zijn gebaseerd op data (datagedreven ontleedsystemen). In het derde deel bekijken we de gevoeligheid van verschillende soorten ontleedsystemen op domeinverschuivingen. De hypothese dat het grammatica-gebaseerde systeem Alpino minder beinvloed wordt door domeinverschuivingen wordt getest, en, dus, dat datagebaseerde systemen meer behoefte hebben aan technieken voor aanpassing aan nieuwe domeinen. Het hoofdstuk laat zien dat Alpino robuust is in vergelijking met de ontleedsystemen die in zijn geheel gebaseerd zijn op geannoteerde data. De laatste bijdrage van dit proefschrift is de ontwikkeling van een meetinstrument om aan te geven in hoeverre twee teksten tot een verschillend of juist tot een vergelijkbaar domein behoren. De meeste studies nemen aan dat er data van het nieuwe domein ter beschikking staat. Dit is echter niet altijd het geval. Daarom evalueren we maten om automatisch geschikte trainingdata te selecteren voor een nieuw domein. De resultaten tonen aan dat een eenvoudige techniek gebaseerd op frequenties van woorden effectief is voor het selecteren van trainingdata voor beide onderzochte talen, het Engels en het Nederlands.",
                "venue": "",
                "year": 2011,
                "referenceCount": 173,
                "citationCount": 38,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Art"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Art",
                        "source": "external"
                    }
                ],
                "authors": [
                    {
                        "authorId": "2065013766",
                        "name": "Barbara Plank"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "f86fac378715207fdcc9c87e2d1d41d18aba5c2c",
                "externalIds": {
                    "CorpusId": 10411766
                },
                "url": "https://www.semanticscholar.org/paper/f86fac378715207fdcc9c87e2d1d41d18aba5c2c",
                "title": "Making Sense of Microposts (#MSM2013)",
                "abstract": "Microposts are small fragments of social media content that have been published using a lightweight paradigm (e.g. Tweets, Facebook likes, foursquare check-ins). Microposts have been used for a variety of applications (e.g., sentiment analysis, opinion mining, trend analysis), by gleaning useful information, often using third-party concept extraction tools. There has been very large uptake of such tools in the last few years, along with the creation and adoption of new methods for concept extraction. However, the evaluation of such e orts has been largely consigned to document corpora (e.g. news articles), questioning the suitability of concept extraction tools and methods for Micropost data. This report describes the Making Sense of Microposts Workshop (#MSM2013) Concept Extraction Challenge, hosted in conjunction with the 2013 World Wide Web conference (WWW'13). The Challenge dataset comprised a manually annotated training corpus of Microposts and an unlabelled test corpus. Participants were set the task of engineering a concept extraction system for a de ned set of concepts. Out of a total of 22 complete submissions 13 were accepted for presentation at the workshop; the submissions covered methods ranging from sequence mining algorithms for attribute extraction to part-of-speech tagging for Micropost cleaning and rule-based and discriminative models for token classi cation. In this report we describe the evaluation process and explain the performance of di erent approaches in di erent contexts.",
                "venue": "",
                "year": 2011,
                "referenceCount": 278,
                "citationCount": 3,
                "influentialCitationCount": 1,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "145971067",
                        "name": "Giuseppe Rizzo"
                    },
                    {
                        "authorId": "1684267",
                        "name": "Raphael Troncy"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Second, we use the Bidir tagger in the combination instead of the MBT tagger (Daelemans et al., 1996) \u2013 the former is significantly more accurate than the latter when tagging Icelandic text."
            ],
            "citingPaper": {
                "paperId": "11f2828fe34dbf8899d7a5260932f312682e7b17",
                "externalIds": {
                    "CorpusId": 16706521
                },
                "url": "https://www.semanticscholar.org/paper/11f2828fe34dbf8899d7a5260932f312682e7b17",
                "title": "Developing a PoS-tagged corpus using existing tools",
                "abstract": "In this paper, we describe the development of a new tagged corpus of Icelandic, consisting of about 1 million tokens. The goal is to use the corpus, among other things, as a new gold standard for training and testing PoS taggers. We describe the individual phases of the corpus construction, i.e. text selection and cleaning, sentence segmentation and tokenisation, PoS tagging with a combination method, error detection, and error correction. Furthermore, we discuss what problems have emerged, highlight which software tools have been found to be useful, and identify which tools are re-usable across different languages. Our preliminary evaluation results show that the error detection programs are effective and that our tagger combination method is crucial with regard to the amount of hand-correction that must be carried out in future work. We believe that our work will be of help to those wishing to develop similar resources for less-resourced languages.",
                "venue": "",
                "year": 2010,
                "referenceCount": 28,
                "citationCount": 26,
                "influentialCitationCount": 2,
                "isOpenAccess": false,
                "fieldsOfStudy": null,
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "1713580",
                        "name": "H. Loftsson"
                    },
                    {
                        "authorId": "2092086579",
                        "name": "J\u00f6kull H. Yngvason"
                    },
                    {
                        "authorId": "3032356",
                        "name": "Sigr\u00fan Helgad\u00f3ttir"
                    },
                    {
                        "authorId": "1883186",
                        "name": "Eir\u00edkur R\u00f6gnvaldsson"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "More recently, taggers that use combination of both Statistical and rule-based [6], Machine learning [7] and Neural Network [8][9] have been developed."
            ],
            "citingPaper": {
                "paperId": "14ff2f4e6e7915f443e4edd92b74c36aa215df39",
                "externalIds": {
                    "MAG": "2460222905",
                    "CorpusId": 59353231
                },
                "url": "https://www.semanticscholar.org/paper/14ff2f4e6e7915f443e4edd92b74c36aa215df39",
                "title": "Automated Tagging System And Tagset Design For Arabic Text",
                "abstract": "This paper presents diacritics rule-based part-of-speech (POS) tagger which automatically tags a partially vocalized Arabic text. The aim is to remove ambiguity and to enable accurate fast automated tagging system. A tagset is being designed in support of this system. Tagset design is at an early stage of research related to automatic morphosyntactic annotation in Arabic language. Preliminary results of the tagset design have been reported in this paper. Arabic language has a valuable and important feature, called diacritics, which are marks placed over and below the letters of Arabic word. This feature plays a great role in adding linguistic attributes to Arabic words and in indicating pronunciation and grammatical function of the words. This feature enriches the language syntactically while removing a great deal of morphological and semantically ambiguities.",
                "venue": "",
                "year": 2010,
                "referenceCount": 20,
                "citationCount": 5,
                "influentialCitationCount": 0,
                "isOpenAccess": false,
                "fieldsOfStudy": [
                    "Computer Science"
                ],
                "s2FieldsOfStudy": [
                    {
                        "category": "Computer Science",
                        "source": "external"
                    },
                    {
                        "category": "Computer Science",
                        "source": "s2-fos-model"
                    },
                    {
                        "category": "Linguistics",
                        "source": "s2-fos-model"
                    }
                ],
                "authors": [
                    {
                        "authorId": "117548168",
                        "name": "Hasan Almuaidi"
                    }
                ]
            }
        }
    ]
}